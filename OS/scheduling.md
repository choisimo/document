제 6장 동기화 도구 (Synchronization Tools)
개요본 장에서는 동기화 도구에 대한 배경 [1], 임계 구역 문제 (Critical-Section Problem) [1], 피터슨의 해결책 (Peterson’s Solution) [1], 하드웨어 지원 [1], 뮤텍스 락 (Mutex Locks) [1], 세마포어 (Semaphores) [1], 그리고 모니터 (Monitors) [1]에 대해 다룹니다.
배경프로세스는 동시에 실행될 수 있습니다 [1]. 프로세스는 언제든지 실행이 부분적으로 완료된 상태로 중단될 수 있습니다 [1]. 공유 데이터에 대한 동시 접근은 데이터 불일치(data inconsistency)를 초래할 수 있습니다 [1]. 데이터 일관성을 유지하기 위해서는 협력하는 프로세스의 순서 있는 실행을 보장하는 메커니즘이 필요합니다 [2]. 제 4장에서 프로듀서-소비자 문제(Bounded Buffer problem)에서 카운터를 사용하는 경우를 통해 이 문제를 설명했습니다 [2]. 프로듀서와 소비자가 카운터를 동시에 업데이트할 때 경합 조건(race condition)이 발생할 수 있습니다 [2].
프로듀서와 소비자 문제프로듀서 코드는 next_produced에 아이템을 생산하고, 버퍼가 가득 차지 않은 동안 (while (counter == BUFFER_SIZE); 조건 만족 시) 버퍼에 아이템을 추가하고 counter를 증가시킵니다 [3]. 소비자 코드는 버퍼가 비어 있지 않은 동안 (while (counter == 0); 조건 만족 시) 버퍼에서 아이템을 꺼내 next_consumed에 할당하고 counter를 감소시킵니다 [3].
경합 조건 (Race Condition) counter++ 연산은 다음과 같이 세 개의 기계어 명령어로 구현될 수 있습니다 [4]:
1.
register1 = counter
2.
register1 = register1 + 1
3.
counter = register1마찬가지로 counter-- 연산은 다음과 같이 세 개의 기계어 명령어로 구현될 수 있습니다 [4]:
4.
register2 = counter
5.
register2 = register2 - 1
6.
counter = register2예를 들어, 초기 count = 5 상태에서 다음 실행 순서를 고려하면 데이터 불일치가 발생합니다 [4]:
•
T0: 프로듀서 register1 = counter 실행 (register1 = 5)
•
T1: 프로듀서 register1 = register1 + 1 실행 (register1 = 6)
•
T2: 소비자 register2 = counter 실행 (register2 = 5)
•
T3: 소비자 register2 = register2 – 1 실행 (register2 = 4)
•
T4: 프로듀서 counter = register1 실행 (counter = 6)
•
T5: 소비자 counter = register2 실행 (counter = 4) 결과적으로 카운터 값은 예상과 다르게 4가 됩니다 [4].
fork() 시스템 호출을 사용하여 자식 프로세스를 생성하는 프로세스 P0과 P1을 생각해 볼 때 [5], 커널 변수 next_available_pid에 대한 경합 조건이 발생할 수 있습니다 [5]. P0과 P1이 next_available_available_pid 변수에 동시에 접근하는 것을 막는 메커니즘이 없다면, 동일한 PID가 두 개의 다른 프로세스에 할당될 수 있습니다 [5].
C 코드 예제에서는 add 함수가 count를 10000번 증가시키고 sub 함수가 count를 10000번 감소시킵니다 [6]. 멀티스레드 환경에서 count 변수를 공유하고 동기화 없이 접근하면, 최종 count 값은 실행할 때마다 6090, 0, 0, -7673, 0 등 예상되는 값인 0과 다르게 나타납니다 [6]. 이는 경합 조건의 실제 예시입니다.
**임계 구역 문제 (Critical Section Problem)**n개의 프로세스 {p0, p1, ..., pn-1}로 구성된 시스템을 생각합니다 [7]. 각 프로세스는 코드의 임계 구역(critical section) 세그먼트를 가지고 있습니다 [7]. 임계 구역에서는 프로세스가 공통 변수를 변경하거나, 테이블을 업데이트하거나, 파일을 쓰는 등의 작업을 수행할 수 있습니다 [7]. 한 프로세스가 임계 구역에서 실행 중일 때 다른 어떤 프로세스도 자신의 임계 구역에 들어갈 수 없어야 합니다 [7]. 임계 구역 문제는 이를 해결하기 위한 프로토콜을 설계하는 것입니다 [7]. 각 프로세스는 진입 구역(entry section)에서 임계 구역에 들어가기 위한 허가를 요청해야 하며, 임계 구역 다음에는 퇴출 구역(exit section)이 오고, 그 후 나머지 구역(remainder section)이 올 수 있습니다 [7, 8].
임계 구역 해결책을 위한 요구사항 [9, 10]
1.
상호 배제 (Mutual Exclusion): 프로세스 Pi가 자신의 임계 구역에서 실행 중이면, 다른 어떤 프로세스도 자신의 임계 구역에서 실행될 수 없습니다 [9].
2.
진행 (Progress): 임계 구역에서 실행 중인 프로세스가 없고, 자신의 임계 구역에 들어가고자 하는 일부 프로세스가 존재한다면, 다음에 임계 구역에 들어갈 프로세스를 선택하는 과정이 무기한 연기되어서는 안 됩니다 [9].
3.
유한 대기 (Bounded Waiting): 프로세스가 임계 구역에 들어가기 위한 요청을 한 후 그 요청이 허가되기까지 다른 프로세스가 자신의 임계 구역에 들어갈 수 있는 횟수에 대한 상한(bound)이 존재해야 합니다 [10]. 어떤 프로세스도 0이 아닌 속도로 실행된다고 가정합니다 [10]. n개의 프로세스의 상대적인 속도에 대해서는 어떠한 가정도 하지 않습니다 [10].
인터럽트 기반 해결책진입 구역에서 인터럽트를 비활성화하고, 퇴출 구역에서 인터럽트를 활성화하는 방법입니다 [11]. 이 방법이 문제를 해결할까요? 임계 구역 코드가 한 시간 동안 실행된다면 어떻게 될까요? [11]. 일부 프로세스가 굶주림(starve) 상태가 되어 임계 구역에 전혀 들어가지 못할 수 있을까요? [11]. CPU가 두 개 있다면 어떻게 될까요? [11].
**소프트웨어 해결책 1 (두 프로세스)**두 프로세스 (P0, P1)를 위한 해결책입니다 [11]. 로드(load) 및 스토어(store) 기계어 명령어가 원자적(atomic), 즉 중단되지 않는다고 가정합니다 [11]. 두 프로세스는 하나의 변수 int turn;을 공유합니다 [11]. turn 변수는 어느 프로세스가 임계 구역에 들어갈 차례인지 나타냅니다 [11]. 초기에는 turn 값이 i (P_i)로 설정됩니다 [11]. (제공된 자료에는 이 해결책의 구체적인 알고리즘 코드가 명시되어 있지 않습니다 [12]). 상호 배제가 보존됩니다 [13]. Pi는 turn == i인 경우에만 임계 구역에 들어갑니다 [13]. turn은 동시에 0과 1일 수 없으므로 상호 배제가 보장됩니다 [13]. 진행 요구사항과 유한 대기 요구사항에 대해서는 질문만 던져져 있습니다 [13].
**소프트웨어 해결책 2 (두 프로세스)**두 프로세스 해결책입니다 [13]. 로드 및 스토어 기계어 명령어가 원자적이라고 가정합니다 [13]. 두 프로세스는 하나의 변수를 공유합니다 (변수 이름이 명시되지 않았으나, 다음 설명에서 flag 배열을 언급합니다) [13]. flag 배열은 프로세스가 임계 구역에 들어갈 준비가 되었는지 나타내는 데 사용됩니다 [13]. 초기에는 flag = flag[1] = false입니다 [13]. flag[i] = true는 프로세스 Pi가 준비되었음을 의미합니다 [13]. (제공된 자료에는 이 해결책의 구체적인 알고리즘 코드가 명시되어 있지 않습니다 [14]).
**피터슨의 해결책 (Peterson’s Solution)**두 프로세스 해결책입니다 [14]. 로드 및 스토어 기계어 명령어가 원자적이라고 가정합니다 [14]. 두 프로세스는 두 개의 변수를 공유합니다: turn 변수는 어느 프로세스가 임계 구역에 들어갈 차례인지 나타내고, flag 배열은 프로세스가 임계 구역에 들어갈 준비가 되었는지 나타냅니다 [14]. flag[i] = true는 프로세스 Pi가 준비되었음을 의미합니다 [14].
프로세스 Pi를 위한 알고리즘 구조는 다음과 같습니다 [15]:
while (true) {
    flag[i] = true; // Pi가 준비됨을 표시
    turn = j; // 상대방에게 차례를 넘김
    while (flag[j] && turn == j); // 상대방이 준비되었고 차례가 상대방이면 대기
    /* critical section */
    flag[i] = false; // Pi가 임계 구역을 빠져나왔음을 표시
    /* remainder section */
}

피터슨 해결책의 정확성 [15] 세 가지 임계 구역 요구사항을 모두 충족함을 증명할 수 있습니다:
1.
상호 배제 보존: Pi는 flag[j]가 false이거나 turn == i인 경우에만 임계 구역에 들어갑니다 [15]. (flag[j]가 true이고 turn == j인 경우에만 대기하므로).
2.
진행 요구사항 만족: 만족합니다 [15].
3.
유한 대기 요구사항 충족: 충족합니다 [15].
피터슨 해결책과 현대 아키텍처알고리즘 시연에는 유용하지만, 피터슨 해결책은 현대 아키텍처에서 작동함을 보장할 수 없습니다 [16]. 성능 향상을 위해 프로세서나 컴파일러는 종속성이 없는 연산의 순서를 재배열(reorder)할 수 있기 때문입니다 [16]. 이것이 왜 작동하지 않는지 이해하는 것은 경합 조건을 더 잘 이해하는 데 유용합니다 [16]. 단일 스레드에서는 결과가 항상 동일하므로 재배열이 괜찮습니다 [16]. 하지만 다중 스레드에서는 재배열이 일관되지 않거나 예상치 못한 결과를 초래할 수 있습니다 [16].
현대 아키텍처 예시 [17, 18] 두 스레드가 boolean flag = false; 및 int x = 0; 데이터를 공유합니다 [17].
•
스레드 1은 while (!flag); print x;를 수행합니다 [17].
•
스레드 2는 x = 100; flag = true;를 수행합니다 [17].예상되는 출력은 100입니다 [17]. 그러나 스레드 2의 flag와 x 변수는 서로 독립적이므로, flag = true;와 x = 100; 명령어는 재배열될 수 있습니다 [18]. 만약 flag = true;가 먼저 실행된 후 스레드 1이 flag를 확인하고 임계 구역에 진입하여 x를 읽는데, 이때 아직 x = 100;이 실행되지 않았다면 출력은 0이 될 수 있습니다 [18].
피터슨 해결책 재조명피터슨 해결책에서 명령어 재배열의 영향은 두 프로세스가 동시에 임계 구역에 들어갈 수 있게 할 수 있습니다 [19]. 현대 컴퓨터 아키텍처에서 피터슨 해결책이 올바르게 작동하도록 보장하려면 동기화 도구를 사용해야 합니다 [19]. C 코드 예제에서는 pthread_mutex_t 대신 피터슨 알고리즘을 사용하여 count를 증가/감소시키는데, 예상 결과는 0이지만 실행할 때마다 0, -1 등 다른 결과가 나올 수 있음을 보여줍니다 [20, 21]. 이는 현대 시스템에서 명령어 재배열로 인해 피터슨 알고리즘이 실패할 수 있음을 시사합니다. (제공된 실행 결과는 항상 0 또는 -1을 보여주는데, 이는 예상치 못한 결과임을 나타냅니다).
**동기화 하드웨어 (Synchronization Hardware)**많은 시스템은 임계 구역 코드를 구현하기 위한 하드웨어 지원을 제공합니다 [22]. 단일 프로세서에서는 인터럽트를 비활성화할 수 있습니다 [22]. 이 경우 현재 실행 중인 코드는 선점되지 않고 실행될 것입니다 [22]. 하지만 다중 프로세서 시스템에서는 일반적으로 비효율적입니다 [22]. 이를 사용하는 운영체제는 확장성이 떨어집니다 [22]. 하드웨어 지원의 세 가지 형태를 살펴볼 것입니다: 1. 하드웨어 명령어, 2. 원자적 변수 (Atomic variables) [22].
**하드웨어 명령어 (Hardware Instructions)**단어의 내용을 원자적으로 (uninterruptedly) 테스트하고 수정하거나, 두 단어의 내용을 원자적으로 교환하는 특별한 하드웨어 명령어입니다 [23]. 예시: Test-and-Set 명령어, Compare-and-Swap 명령어 [23].
test_and_set() 명령어정의: boolean test_and_set (boolean *target) { boolean rv = *target; *target = true; return rv; } [23]. 속성: 원자적으로 실행됩니다 [23]. 전달된 매개변수의 원래 값을 반환합니다 [23]. 전달된 매개변수의 새 값을 true로 설정합니다 [23].
test_and_set()을 사용한 해결책공유된 부울 변수 lock을 사용하며, 초기값은 false입니다 [24]. 해결책 구조:
do {
    /* 진입 구역 */
    while (test_and_set(&lock)); // lock이 false가 될 때까지 대기하고 true로 설정
    /* 임계 구역 */
    /* 퇴출 구역 */
    lock = false; // lock을 false로 해제
    /* 나머지 구역 */
} while (true);

이것이 임계 구역 문제를 해결할까요? [24]. (이 해결책은 상호 배제는 보장하지만, 바쁜 대기(busy waiting)를 유발하며, 진행(Progress)과 유한 대기(Bounded Waiting) 요구사항을 만족하는지는 추가 검토가 필요합니다. 특히 유한 대기는 만족하지 못할 수 있습니다).
**뮤텍스 락 (Mutex Locks)**이전 해결책들은 복잡하고 일반적으로 애플리케이션 프로그래머에게 접근하기 어렵습니다 [24]. OS 설계자는 임계 구역 문제를 해결하기 위한 소프트웨어 도구를 구축합니다 [24]. 가장 간단한 것이 뮤텍스 락입니다 [24]. 뮤텍스 락은 락이 사용 가능한지 여부를 나타내는 부울 변수입니다 [24]. 임계 구역을 보호하기 위해 락을 먼저 acquire()하고, 임계 구역을 빠져나온 후 release()합니다 [24]. acquire() 및 release() 호출은 원자적이어야 합니다 [24]. 일반적으로 compare-and-swap과 같은 하드웨어 원자적 명령어를 통해 구현됩니다 [24]. 그러나 이 해결책은 바쁜 대기(busy waiting)를 필요로 합니다 [25]. 따라서 이 락은 **스핀락(spinlock)**이라고도 불립니다 [25].
뮤텍스 락을 사용한 임계 구역 문제 해결책 [25]acquire() 및 release() 함수는 원자적으로 구현되어야 합니다 [25]. test-and-set 및 compare-and-swap 모두 이 함수들을 구현하는 데 사용될 수 있습니다 [25]. 구조:
while (true) {
    acquire(lock);
    /* critical section */
    release(lock);
    /* remainder section */
}
acquire() 함수: while (!available); available = false; (available은 락의 상태를 나타내는 부울 변수) [25]
release() 함수: available = true; [25]

C 코드 예제에서는 pthread_mutex_t를 사용한 뮤텍스 락을 보여줍니다 [26]. pthread_mutex_init()으로 뮤텍스를 초기화하고 [26], 임계 구역(count++ 연산 부분) 진입 전에 pthread_mutex_lock()으로 락을 획득하고 [26], 임계 구역을 빠져나온 후 pthread_mutex_unlock()으로 락을 해제합니다 [26]. 이 코드를 실행하면 경합 조건 없이 count 값이 예상대로 20 (각 스레드가 10번 증가) 또는 2000000 (각 스레드가 1000000번 증가)이 되는 것을 확인할 수 있습니다 [27-29].
**세마포어 (Semaphore)**세마포어는 프로세스가 활동을 동기화하기 위한 뮤텍스 락보다 더 정교한 방법을 제공하는 동기화 도구입니다 [30]. 세마포어 S는 정수 변수입니다 [30]. 세마포어는 두 가지 불가분 (atomic) 연산, wait()와 signal()을 통해서만 접근할 수 있습니다 [30]. 원래는 P()와 V()라고 불렸습니다 [30].
wait() 연산의 정의: [30]
wait(S) {
    while (S <= 0); // S가 0보다 커질 때까지 바쁜 대기
    S--; // S 값을 감소
}

signal() 연산의 정의: [30]
signal(S) {
    S++; // S 값을 증가
}

세마포어 사용
•
카운팅 세마포어 (Counting semaphore): 정수 값이 제한되지 않은 도메인에 걸쳐 범위가 지정될 수 있습니다 [31].
•
이진 세마포어 (Binary semaphore): 정수 값이 0과 1 사이에서만 범위가 지정될 수 있습니다 [31]. 이진 세마포어는 뮤텍스 락과 같습니다 [31]. 카운팅 세마포어 S는 이진 세마포어로 구현될 수 있습니다 [31]. 세마포어를 사용하여 다양한 동기화 문제를 해결할 수 있습니다 [31].
세마포어 사용 예시임계 구역 문제 해결: mutex라는 세마포어를 1로 초기화합니다 [32]. 임계 구역 진입 전에 wait(mutex);를 호출하고, 임계 구역 이후에 signal(mutex);를 호출합니다 [32]. S1이 S2보다 먼저 발생해야 하는 요구사항이 있는 P1과 P2를 생각해 봅니다 [32]. synch라는 세마포어를 0으로 초기화합니다 [32]. P1은 S1을 실행한 후 signal(synch);를 호출합니다 [32]. P2는 wait(synch);를 호출한 후 S2를 실행합니다 [32]. P1이 signal(synch)를 호출하기 전까지 P2는 wait(synch)에서 대기하므로, S1이 S2보다 먼저 실행됨이 보장됩니다 [32].
세마포어 구현동일한 세마포어에 대해 두 프로세스가 동시에 wait() 및 signal()을 실행할 수 없도록 보장해야 합니다 [33]. 따라서 구현 자체는 wait 및 signal 코드가 임계 구역에 배치되는 임계 구역 문제가 됩니다 [33]. 이제 임계 구역 구현에서 바쁜 대기가 발생할 수 있습니다 [33]. 그러나 구현 코드는 짧습니다 [33]. 임계 구역이 거의 점유되지 않으면 바쁜 대기가 거의 발생하지 않습니다 [33]. 애플리케이션이 임계 구역에서 많은 시간을 보낼 수 있으므로, 이 해결책은 좋지 않습니다 [33].
바쁜 대기 없는 세마포어 구현각 세마포어에는 연결된 대기 큐(waiting queue)가 있습니다 [34]. 대기 큐의 각 항목은 두 가지 데이터 항목을 가집니다: 값 (정수 타입) 및 목록의 다음 레코드에 대한 포인터 [34]. 두 가지 연산:
•
block: 해당 연산을 호출하는 프로세스를 적절한 대기 큐에 배치합니다 [34].
•
wakeup: 대기 큐에 있는 프로세스 중 하나를 제거하고 준비 큐(ready queue)에 배치합니다 [34]. 세마포어 구조체 정의: typedef struct { int value; struct process *list; } semaphore; [34]. 바쁜 대기 없는 wait(semaphore *S): S->value--; if (S->value < 0) { // 프로세스를 S->list에 추가; block(); } [35]. S->value가 음수가 되면 대기자가 있다는 의미입니다. 바쁜 대기 없는 signal(semaphore *S): S->value++; if (S->value <= 0) { // S->list에서 프로세스 P 제거; wakeup(P); } [35]. S->value가 0 이하이면 대기자가 있다는 의미입니다.
C 코드 예제에서는 sem_t를 사용한 세마포어를 보여줍니다 [36]. sem_init(&s, 0, 1);로 이진 세마포어(초기값 1)를 초기화합니다 [36]. 임계 구역(count++) 진입 전에 sem_wait(&s);를 호출하고 [36], 임계 구역 후 sem_post(&s);를 호출합니다 [36]. 이 코드를 실행하면 count 값이 예상대로 2000000이 되는 것을 확인할 수 있습니다 [36]. 또 다른 예제에서는 3개의 스레드와 초기값 3인 세마포어를 사용하여 count를 증가시키며, 최종 count는 30이 됩니다 [37, 38].
세마포어 문제점세마포어 연산의 잘못된 사용:
•
signal(mutex) ... wait(mutex): 여러 프로세스가 임계 구역에서 동시에 실행될 수 있습니다 [39]. (mutex 초기값이 1이고 한 프로세스가 signal 먼저 하면 mutex 값이 2가 되어 다른 프로세스들이 wait에서 통과할 수 있게 됩니다).
•
wait(mutex) ... wait(mutex): 프로세스가 두 번째 wait() 호출에서 영구적으로 블록됩니다 [39]. (첫 번째 wait에서 mutex 값이 0이 되어 두 번째 wait에서는 대기하게 됩니다).
•
wait(mutex) 및/또는 signal(mutex) 누락: 잘못된 사용으로 인해 예상치 못한 결과가 발생합니다 [39]. 이 외에도 세마포어 및 다른 동기화 도구를 잘못 사용하면 발생할 수 있는 예시들입니다 [39].
**모니터 (Monitors)**모니터는 프로세스 동기화를 위한 편리하고 효과적인 메커니즘을 제공하는 고수준 추상화입니다 [40]. 추상 데이터 타입이며, 내부 변수는 프로시저 내의 코드에서만 접근할 수 있습니다 [40]. 한 번에 하나의 프로세스만 모니터 내에서 활성 상태일 수 있습니다 (상호 배제) [40].
모니터의 의사 코드 구문: [40, 41]
monitor monitor-name {
    // 공유 변수 선언 (shared variable declarations)
    procedure P1 (…) { …. }
    procedure P2 (…) { …. }
    …
    procedure Pn (…) {……}
    initialization code (…) { … }
}

모니터의 개략적인 모습 그림 [41].
세마포어를 사용한 모니터 구현 [42] 변수: semaphore mutex; // initially = 1, semaphore next; // initially = 0, int next_count = 0; // number of processes waiting inside the monitor [42]. 각 프로시저 P는 다음과 같이 대체됩니다 [42]:
wait(mutex);
…
body of P;
…
if (next_count > 0)
    signal(next);
else
    signal(mutex);

모니터 내에서 상호 배제가 보장됩니다 [42].
조건 변수 (Condition Variables) condition x, y;와 같은 조건 변수가 있습니다 [43]. 조건 변수에는 두 가지 연산이 허용됩니다 [43, 44]:
•
x.wait(): 연산을 호출한 프로세스는 x.signal()이 호출될 때까지 중단(suspended)됩니다 [43, 44].
•
x.signal(): x.wait()를 호출했던 프로세스 중 하나(만약 있다면)를 다시 시작(resume)시킵니다 [43, 44]. 변수에 대해 x.wait()가 없다면, 해당 변수에 아무런 영향을 미치지 않습니다 [43, 44]. 조건 변수는 모니터와 함께 사용됩니다 [44]. 모니터는 조건 변수를 포함할 수 있습니다 [44].
조건 변수 사용 예시S1이 S2보다 먼저 실행되어야 하는 P1과 P2를 생각해 봅니다 [45]. P1과 P2에 의해 각각 호출되는 F1 및 F2 두 프로시저를 가진 모니터를 생성합니다 [45]. 하나의 조건 변수 x를 0으로 초기화하고, 하나의 부울 변수 done을 사용합니다 [45].
•
F1: S1; done = true; x.signal(); [45].
•
F2: if done == false x.wait(); S2; [45]. done이 false이면 F2는 x.wait()에서 대기하고, F1이 S1을 완료하고 done을 true로 설정한 후 x.signal()을 호출하면 F2가 다시 시작되어 S2를 실행합니다.
**구현 - 조건 변수 (Implementation – Condition Variables)**각 조건 변수 x에 대해 semaphore x_sem; // initially = 0, int x_count = 0; 변수를 가집니다 [42].x.wait() 연산은 다음과 같이 구현될 수 있습니다 [42]:
x_count++; // 대기 중인 프로세스 수 증가
if (next_count > 0) // 모니터 진입 시 기다리는 프로세스가 있다면
    signal(next); // 그 프로세스에게 signal
else // 없다면
    signal(mutex); // 모니터 락 해제
wait(x_sem); // 자신의 세마포어에서 대기
x_count--; // 다시 시작되면 대기 중인 프로세스 수 감소

x.signal() 연산은 다음과 같이 구현될 수 있습니다 [46]:
if (x_count > 0) { // 대기 중인 프로세스가 있다면
    next_count++; // 모니터 내에서 signal 호출 후 대기할 프로세스 수 증가
    signal(x_sem); // 대기 중인 프로세스 하나를 깨움
    wait(next); // 자신은 next 세마포어에서 대기 (모니터의 상호 배제 유지)
    next_count--; // 대기에서 풀려났으므로 next 대기 수 감소
}

**모니터 내에서 프로세스 다시 시작 (Resuming Processes within a Monitor)**여러 프로세스가 조건 변수 x에서 큐에 있고 x.signal()이 실행되면, 어떤 프로세스가 다시 시작되어야 할까요? [47]. FCFS(선입선출)는 종종 적절하지 않습니다 [47]. x.wait(c) 형태의 조건부 대기(conditional-wait) 구조를 사용합니다 [47]. 여기서 c는 정수(우선순위 번호)이며, 가장 낮은 번호(가장 높은 우선순위)를 가진 프로세스가 다음에 스케줄링됩니다 [47].
**단일 자원 할당 (Single Resource allocation)**우선순위 번호(프로세스가 자원을 사용할 계획인 최대 시간 지정)를 사용하여 경쟁하는 프로세스 간에 단일 자원을 할당합니다 [47, 48]. R은 ResourceAllocator 타입의 인스턴스입니다 [47, 48]. R.acquire(t); ... access the resource; ... R.release; 형태로 사용합니다 [47-49]. 여기서 t는 프로세스가 자원을 사용할 계획인 최대 시간입니다 [48]. 가장 짧은 시간을 가진 프로세스가 먼저 자원을 할당받습니다 [48].
ResourceAllocator 모니터 구조: [49]
monitor ResourceAllocator {
    boolean busy;
    condition x; // 조건 변수

    void acquire(int time) {
        if (busy) // 자원이 사용 중이면
            x.wait(time); // time을 우선순위로 대기
        busy = true; // 자원 획득
    }

    void release() {
        busy = false; // 자원 해제
        x.signal(); // 대기 중인 프로세스 하나를 깨움 (우선순위 높은 순)
    }

    initialization code() {
        busy = false; // 초기에는 자원 사용 가능
    }
}

사용법은 acquire; ... release;입니다 [49]. 잘못된 모니터 연산 사용: release() ... acquire(), acquire() ... acquire(), acquire() 및/또는 release() 누락 [49].
**활성 상태 (Liveness)**프로세스는 뮤텍스 락이나 세마포어와 같은 동기화 도구를 획득하려 할 때 무기한 대기해야 할 수 있습니다 [50]. 무기한 대기는 본 장 초반에 논의된 진행(progress) 및 유한 대기(bounded-waiting) 기준을 위반합니다 [50]. 활성 상태는 시스템이 프로세스의 진행을 보장하기 위해 충족해야 하는 속성 집합을 의미합니다 [50]. 무기한 대기는 활성 상태 실패의 예시입니다 [50].
교착 상태 (Deadlock): 둘 이상의 프로세스가 대기 중인 프로세스 중 하나만이 유발할 수 있는 이벤트를 무기한 기다리는 상태입니다 [51]. S와 Q 두 세마포어를 1로 초기화했다고 가정합니다 [51]. P0은 wait(S)를 호출하고 wait(Q)를 호출하며, P1은 wait(Q)를 호출하고 wait(S)를 호출합니다 [51]. 만약 P0가 wait(S)를 실행하고 P1이 wait(Q)를 실행한다면 [51], P0는 P1이 signal(Q)를 실행할 때까지 기다려야 하지만, P1은 P0가 signal(S)를 실행할 때까지 기다립니다 [51]. 이러한 signal() 연산은 결코 실행되지 않으므로, P0와 P1은 교착 상태에 빠집니다 [51].
다른 형태의 교착 상태:
•
굶주림 (Starvation): 무기한 블록킹 [52]. 프로세스가 중단된 세마포어 큐에서 결코 제거되지 않을 수 있습니다 [52].
•
우선순위 역전 (Priority Inversion): 우선순위가 낮은 프로세스가 우선순위가 높은 프로세스가 필요로 하는 락을 보유하는 스케줄링 문제입니다 [52]. 우선순위 상속 프로토콜(priority-inheritance protocol)을 통해 해결됩니다 [52].
고전적인 동기화 문제 [53] 새로 제안된 동기화 스키마를 테스트하는 데 사용되는 고전적인 문제입니다 [53]:
•
유한 버퍼 문제 (Bounded-Buffer Problem) [53].
•
읽기-쓰기 문제 (Readers and Writers Problem) [53].
•
식사하는 철학자 문제 (Dining-Philosophers Problem) [53].
유한 버퍼 문제 [54-56] 각각 하나의 아이템을 저장할 수 있는 n개의 버퍼가 있습니다 [54]. 프로듀서/소비자 문제로도 불립니다 [54]. 프로듀서는 소비자를 위해 가득 찬 버퍼를 생산하고 [54], 소비자는 프로듀서를 위해 빈 버퍼를 생산합니다 [54].
•
semaphore mutex는 1로 초기화됩니다 [54]. 버퍼 풀 접근에 대한 상호 배제를 제공합니다 [54].
•
semaphore full은 0으로 초기화됩니다 [54]. 가득 찬 버퍼 수를 카운트합니다 [54].
•
semaphore empty는 n으로 초기화됩니다 [54]. 빈 버퍼 수를 카운트합니다 [54]. 프로듀서 프로세스의 구조 [55]: 아이템 생산 후 wait(empty); wait(mutex);를 호출하여 빈 버퍼와 버퍼 접근 락을 획득하고, 버퍼에 아이템을 추가한 후 signal(mutex); signal(full);을 호출하여 락을 해제하고 가득 찬 버퍼 수를 증가시킵니다. 소비자 프로세스의 구조 [56]: wait(full); wait(mutex);를 호출하여 가득 찬 버퍼와 버퍼 접근 락을 획득하고, 버퍼에서 아이템을 제거한 후 signal(mutex); signal(empty);를 호출하여 락을 해제하고 빈 버퍼 수를 증가시킨 후, 아이템을 소비합니다. C 코드 예제는 pthread_mutex_t와 sem_t를 사용하여 유한 버퍼 문제를 구현합니다 [56, 57]. BUFFER_SIZE는 5로 정의됩니다 [56]. set 함수는 프로듀서가 호출하여 아이템을 버퍼에 넣고 [56], get 함수는 소비자가 호출하여 아이템을 버퍼에서 꺼냅니다 [56]. 실행 예시 출력도 포함됩니다 [58, 59]. Java 코드 예제는 synchronized, wait(), notify()를 사용하여 유한 버퍼 문제를 구현합니다 [60-69]. SynchronizedBuffer 클래스는 Buffer 인터페이스를 구현하며 [61, 65], buffer 변수와 occupiedBuffers 변수를 공유합니다 [65]. set 메서드(synchronized)는 버퍼가 가득 찬 경우(occupiedBuffers == 1) wait()로 대기하고, 아이템을 넣은 후 occupiedBuffers를 증가시키고 notify()를 호출합니다 [65-67]. get 메서드(synchronized)는 버퍼가 비어 있는 경우(occupiedBuffers == 0) wait()로 대기하고, 아이템을 꺼낸 후 occupiedBuffers를 감소시키고 notify()를 호출합니다 [63, 64]. SharedBufferTest 클래스는 프로듀서와 소비자 스레드를 생성하고 실행하는 메인 클래스입니다 [68, 69]. 실행 예시 출력을 통해 프로듀서가 쓰고 소비자가 읽는 과정을 확인할 수 있습니다 [69, 70].
읽기-쓰기 문제 (Readers-Writers Problem) [71] 많은 동시 프로세스 간에 데이터 세트가 공유됩니다 [71]. 읽기 프로세스(Readers)는 데이터 세트만 읽고 업데이트하지 않습니다 [71]. 쓰기 프로세스(Writers)는 읽고 쓸 수 있습니다 [71]. 문제는 여러 읽기 프로세스가 동시에 읽을 수 있도록 허용하는 것입니다 [71]. 쓰기 프로세스는 공유 데이터에 한 번에 하나만 접근할 수 있습니다 [71]. 읽기 및 쓰기 프로세스를 고려하는 몇 가지 변형이 있으며, 모두 어떤 형태의 우선순위를 포함합니다 [71].
공유 데이터: 데이터 세트 [72], semaphore rw_mutex (1로 초기화) - 읽기 및 쓰기 프로세스 모두에 공통 [72], semaphore mutex (1로 초기화) - read_count 변수가 업데이트될 때 상호 배제를 보장 [72], int read_count (0으로 초기화) - 현재 객체를 읽고 있는 프로세스 수를 추적 [72].
쓰기 프로세스의 구조 [72]: while (true) { wait(rw_mutex); /* writing is performed */ signal(rw_mutex); }. 쓰기 프로세스는 rw_mutex 락을 획득해야만 쓸 수 있으며, 락을 해제한 후 다른 쓰기 프로세스나 읽기 프로세스가 접근할 수 있습니다.
읽기 프로세스의 구조 [73]: while (true) { wait(mutex); read_count++; if (read_count == 1) /* 첫 번째 읽기 프로세스 */ wait(rw_mutex); signal(mutex); /* reading is performed */ wait(mutex); read_count--; if (read_count == 0) /* 마지막 읽기 프로세스 */ signal(rw_mutex); signal(mutex); }. 읽기 프로세스는 mutex를 획득하여 read_count를 증가시키고, 첫 번째 읽기 프로세스인 경우에만 rw_mutex를 획득하여 쓰기 프로세스가 접근하지 못하도록 막습니다. 읽기를 수행한 후 다시 mutex를 획득하여 read_count를 감소시키고, 마지막 읽기 프로세스인 경우에만 rw_mutex를 해제하여 쓰기 프로세스가 접근할 수 있도록 합니다.
읽기-쓰기 문제 변형: 이전 슬라이드의 해결책은 쓰기 프로세스가 결코 쓰지 못하는 상황(굶주림)을 초래할 수 있으며, 이를 "첫 번째 읽기-쓰기" 문제라고 합니다 [74]. "두 번째 읽기-쓰기" 문제는 첫 번째 읽기-쓰기 문제의 변형으로, 쓰기 프로세스가 쓰기 준비가 되면 새로 도착한 읽기 프로세스는 읽을 수 없도록 합니다 [74]. 첫 번째와 두 번째 문제 모두 굶주림을 초래할 수 있어 더 많은 변형이 발생합니다 [74]. 일부 시스템에서는 커널이 읽기-쓰기 락을 제공하여 이 문제를 해결합니다 [74].
식사하는 철학자 문제 (Dining-Philosophers Problem) [75] N명의 철학자가 둥근 테이블에 앉아 있으며, 가운데에는 쌀이 담긴 그릇이 있습니다 [75]. 그들은 생각하고 먹는 것을 번갈아 가며 평생을 보냅니다 [75]. 그들은 이웃과 상호작용하지 않습니다 [75]. 가끔씩 그릇에서 먹기 위해 젓가락 두 개(한 번에 하나씩)를 집으려 합니다 [75]. 먹으려면 두 개 모두 필요하고, 다 먹으면 둘 다 내려놓습니다 [75]. 5명의 철학자의 경우, 공유 데이터는 쌀 그릇(데이터 세트)과 1로 초기화된 semaphore chopstick[4]입니다 [75].
식사하는 철학자 문제 알고리즘 (세마포어 해결책) [76] 철학자 i의 구조:
while (true) {
    wait(chopstick[i]); // 왼쪽 젓가락을 잡습니다
    wait(chopstick[(i + 1) % 5]); // 오른쪽 젓가락을 잡습니다
    /* eat for awhile */ // 잠시 식사합니다
    signal(chopstick[i]); // 왼쪽 젓가락을 내려놓습니다
    signal(chopstick[(i + 1) % 5]); // 오른쪽 젓가락을 내려놓습니다
    /* think for awhile */ // 잠시 생각합니다
}

이 알고리즘의 문제는 무엇일까요? [76]. 다섯 명의 철학자가 모두 동시에 배가 고파진다면? [76]. 각자 왼쪽 젓가락을 잡고 오른쪽 젓가락을 잡으려 할 때 교착 상태가 발생할 수 있습니다 [76]. 모든 철학자가 왼쪽 젓가락을 잡고 상대방이 들고 있는 오른쪽 젓가락을 기다리게 됩니다.
교착 상태 문제에 대한 몇 가지 해결책: [77]
•
테이블에 동시에 앉을 수 있는 철학자 수를 최대 네 명으로 제한합니다 [77].
•
철학자가 두 젓가락이 모두 사용 가능한 경우에만 젓가락을 집을 수 있도록 허용합니다 (이를 위해 임계 구역에서 집어야 합니다) [77].
•
비대칭 해결책을 사용합니다 [77]. 홀수 번호 철학자는 먼저 왼쪽 젓가락을 집고 그 다음에 오른쪽 젓가락을 집습니다 [77]. 짝수 번호 철학자는 오른쪽 젓가락을 집고 그 다음에 왼쪽 젓가락을 집습니다 [77].
식사하는 철학자 문제 - 모니터 해결책 [78-81] 철학자는 두 젓가락이 모두 사용 가능한 경우에만 젓가락을 집을 수 있습니다 [78]. 철학자가 있을 수 있는 세 가지 상태를 구분해야 합니다 [78]. enum {THINKING, HUNGRY, EATING} state [4]; [78]. 철학자 i는 자신의 두 이웃이 식사 중이 아닌 경우에만 변수 state[i] = EATING으로 설정할 수 있습니다 [78]: state[(i+4) % 5] != EATING) and (state[(i+1)%5]!= EATING).
철학자 i가 배가 고프지만 필요한 젓가락을 얻을 수 없을 때 자신을 지연시킬 수 있도록 합니다 [79]. condition self[4]; [79].
DiningPhilosophers 모니터 구조: [80]
•
state 배열과 self 조건 변수 사용 [80].
•
test(int i) 함수: 철학자 i의 상태가 HUNGRY이고 이웃(i-1, i+1)이 EATING 상태가 아니면, 철학자 i의 상태를 EATING으로 변경하고 self[i].signal()을 호출하여 해당 철학자를 깨웁니다 [80].
•
pickup(int i) 함수: wait(mutex)를 호출하여 모니터 진입 락을 획득하고, 철학자 i의 상태를 HUNGRY로 변경합니다 [80]. test(i)를 호출하여 식사 가능한지 확인하고, 상태가 EATING이 아니면(if (state[i] != EATING)) self[i].wait를 호출하여 대기합니다 [80]. wait에서 풀려나면 signal(mutex)를 호출하여 모니터 락을 해제합니다 [80]. (제공된 슬라이드에는 wait/signal(mutex) 호출 순서가 약간 불명확하게 제시되어 있습니다. 모니터 구현의 표준은 진입 시 wait(mutex), 퇴출 시 signal(mutex)입니다. wait(self[i])는 모니터 내에서 mutex를 해제하고 대기했다가 다시 획득하며, signal(self[i])는 대기 중인 프로세스를 깨우지만 mutex는 해제하지 않습니다. 슬라이드의 의사 코드는 이 표준을 따르는 것으로 보입니다 [80]).
•
putdown(int i) 함수: wait(mutex)를 호출하여 모니터 락을 획득하고, 철학자 i의 상태를 THINKING으로 변경합니다 [80]. test 함수를 호출하여 이웃(i-1, i+1)이 이제 식사할 수 있는지 확인하고 신호를 보냅니다 [80]. signal(mutex)를 호출하여 락을 해제합니다 [80].
•
초기화 코드: 모든 철학자의 상태를 THINKING으로 설정합니다 [81].
솔루션 사용법: 각 철학자 "i"는 다음 순서로 pickup() 및 putdown() 연산을 호출합니다 [81]: DiningPhilosophers.pickup(i); /** EAT **/ DiningPhilosophers.putdown(i);. 이 해결책은 교착 상태는 없지만, 굶주림은 가능합니다 [81]. (예를 들어, HUNGRY 상태의 철학자들 사이에 특정 패턴으로 인해 일부 철학자가 계속 젓가락을 얻지 못할 수 있습니다). C 코드 예제는 pthread_mutex_t 및 pthread_cond_t를 사용하여 모니터 기반 식사하는 철학자 문제를 구현합니다 [82, 83]. init 함수에서 상태 배열과 조건 변수, 뮤텍스를 초기화합니다 [82]. test, pickup, putdown 함수는 모니터 의사 코드의 로직을 따르며, pthread_cond_wait 및 pthread_cond_signal을 사용합니다 [82, 83]. philosopher 함수는 각 철학자의 루틴을 구현하며, 생각하고, 젓가락을 집고, 식사하고, 젓가락을 내려놓는 과정을 반복합니다 [83].
제 8장 교착 상태 (Deadlocks)
개요본 장에서는 시스템 모델 [84], 교착 상태 특성 [84], 교착 상태 처리 방법 [84], 교착 상태 예방 [84], 교착 상태 회피 [84], 교착 상태 탐지 [84], 그리고 교착 상태로부터의 복구 [84]를 다룹니다.
시스템 모델시스템은 자원으로 구성됩니다 [85]. 자원 유형 R1, R2, ..., Rm (CPU 사이클, 메모리 공간, I/O 장치 등)이 있습니다 [85]. 각 자원 유형 Ri는 Wi개의 인스턴스를 가집니다 [85]. 각 프로세스는 다음과 같이 자원을 활용합니다: 요청(request), 사용(use), 해제(release) [85].
다중 스레드 애플리케이션에서의 교착 상태 [86, 87] 데이터: 1로 초기화된 세마포어 S1과 1로 초기화된 세마포어 S2 [86]. 두 스레드 T1과 T2 [86].
•
T1: wait(s1); wait(s2); [86].
•
T2: wait(s2); wait(s1); [86].스레드 1이 first_mutex(s1에 해당)를 획득하고 스레드 2가 second_mutex(s2에 해당)를 획득하면 교착 상태가 발생할 수 있습니다 [87]. 그 후 스레드 1은 second_mutex를 기다리고 스레드 2는 first_mutex를 기다리게 됩니다 [87]. 이는 자원 할당 그래프로 설명될 수 있습니다 [87].
**라이브락 (Livelock)**스레드가 계속해서 실패하는 작업을 시도할 때 발생합니다 [88]. C 코드 예제는 두 스레드가 pthread_mutex_lock과 pthread_mutex_trylock을 사용하여 두 개의 뮤텍스 (first_mutex, second_mutex)를 교차적으로 획득하려 하지만, 서로 상대방이 필요한 락을 먼저 획득하지 못해 계속해서 락을 획득하려 시도하다가 실패하는 과정을 보여줍니다 [88, 89]. while(done) 루프가 계속 실행되지만(done은 초기값 0으로 루프 실행 안 됨. 코드 오류로 보임. while(!done) 또는 done=0; while(!done)이어야 할 듯), 어떤 스레드도 작업을 완료(done=1)하지 못하고 계속 상태만 바꿉니다. (소스 코드의 while(done)은 done이 초기값 0이므로 루프가 실행되지 않게 되어 있어 라이브락 예제로 부적절해 보입니다. 의도상 while(!done)이어야 할 것입니다).
교착 상태 특성 (Deadlock Characterization) 교착 상태는 네 가지 조건이 동시에 성립될 때 발생할 수 있습니다 [90].
1.
상호 배제 (Mutual exclusion): 한 번에 하나의 스레드만 자원을 사용할 수 있습니다 [90]. 공유 가능한 자원(예: 읽기 전용 파일)에는 필요하지 않지만, 공유 불가능한 자원에는 필수적입니다 [91].
2.
점유와 대기 (Hold and wait): 하나 이상의 자원을 보유하고 있는 스레드가 다른 스레드가 보유한 추가 자원을 획득하기 위해 대기하고 있습니다 [90].
3.
비선점 (No preemption): 자원은 해당 자원을 보유한 스레드에 의해서만 자발적으로 해제될 수 있으며, 해당 스레드가 작업을 완료한 후 해제됩니다 [90].
4.
순환 대기 (Circular wait): 대기 중인 스레드 집합 {T0, T1, ..., Tn}이 존재하여, T0는 T1이 보유한 자원을, T1은 T2가 보유한 자원을, ..., Tn-1은 Tn이 보유한 자원을, 그리고 Tn은 T0가 보유한 자원을 대기하고 있는 상태입니다 [90].
**자원 할당 그래프 (Resource-Allocation Graph)**꼭짓점 V는 시스템의 모든 스레드 집합 T와 모든 자원 유형 집합 R로 나뉩니다 [92].
•
요청 간선(request edge): Ti → Rj는 스레드 Ti가 자원 Rj를 요청함을 나타내는 방향 간선입니다 [92].
•
할당 간선(assignment edge): Ti ← Rj는 자원 Rj가 스레드 Ti에 할당되었음을 나타내는 방향 간선입니다 [92]. 예시 자원 할당 그래프: R1 1개, R2 2개, R3 1개, R4 3개 인스턴스 [93]. T1은 R2 1개를 보유하고 R1 인스턴스를 대기 중 [93]. T2는 R1 1개, R2 1개를 보유하고 R3 인스턴스를 대기 중 [93]. T3는 R3 1개를 보유 [93]. 자원 할당 그래프에 교착 상태가 있는 예시 그림 [93]. 자원 할당 그래프에 사이클이 있지만 교착 상태가 없는 예시 그림 (여러 인스턴스) [93].기본 사실: 그래프에 사이클이 없으면 교착 상태가 없습니다 [94]. 그래프에 사이클이 있으면 교착 상태 가능성이 있습니다 [94]. 자원 유형당 인스턴스가 하나만 있는 경우 사이클은 교착 상태를 의미합니다 [94]. 자원 유형당 여러 인스턴스가 있는 경우 사이클은 교착 상태 가능성을 의미합니다 [94].
교착 상태 처리 방법 [94, 95]
1.
시스템이 절대로 교착 상태에 들어가지 않도록 보장합니다: 교착 상태 예방(Deadlock prevention) 또는 교착 상태 회피(Deadlock avoidance) [94].
2.
시스템이 교착 상태에 들어가도록 허용하고 나중에 복구합니다 [94].
3.
문제를 무시하고 시스템에 교착 상태가 절대 발생하지 않는다고 가정합니다 [94]. (대부분의 운영체제에서 사용하는 접근 방식입니다. 성능 저하를 감수하기 어렵기 때문입니다).
**교착 상태 예방 (Deadlock Prevention)**교착 상태를 발생시키는 네 가지 필수 조건 중 하나를 무효화합니다 [91].
•
상호 배제 (Mutual Exclusion): 공유 가능한 자원에는 필요하지 않지만, 공유 불가능한 자원에는 필수적입니다 [91]. 이 조건을 항상 무효화하기는 어렵습니다.
•
점유와 대기 (Hold and Wait): 프로세스가 자원을 요청할 때 다른 자원을 보유하고 있지 않도록 보장해야 합니다 [91]. 방법: 1) 프로세스가 실행을 시작하기 전에 필요한 모든 자원을 요청하고 할당받도록 요구하거나, 2) 프로세스가 할당된 자원이 없을 때만 자원을 요청하도록 허용합니다 [91]. 단점: 자원 활용률이 낮아지고 굶주림 가능성이 있습니다 [91].
•
비선점 (No Preemption): 자원을 보유한 프로세스가 즉시 할당받을 수 없는 다른 자원을 요청하는 경우, 현재 보유하고 있는 모든 자원을 해제합니다 [96]. 선점된 자원은 프로세스가 대기하는 자원 목록에 추가됩니다 [96]. 프로세스는 이전 자원과 요청하는 새 자원을 모두 다시 얻을 수 있을 때만 다시 시작됩니다 [96].
•
순환 대기 (Circular Wait): 모든 자원 유형에 대한 총 순서(total ordering)를 부과하고, 각 프로세스가 열거 순서에 따라 오름차순으로 자원을 요청하도록 요구합니다 [96]. 가장 일반적인 방법입니다 [97]. 각 자원(예: 뮤텍스 락)에 고유한 번호를 할당합니다 [97]. 자원은 순서대로 획득해야 합니다 [97]. 예: first_mutex = 1, second_mutex = 5일 때, 스레드 2는 second_mutex를 먼저 획득하는 코드를 작성할 수 없습니다 [97]. transaction 함수 예시: checking account에서 savings account로, savings account에서 checking account로 동시에 이체하는 두 스레드가 다른 순서로 락을 획득하면 교착 상태가 발생할 수 있습니다 [97]. (예방을 위해) 락은 항상 동일한 순서로 획득해야 합니다.
**교착 상태 회피 (Deadlock Avoidance)**시스템이 추가적인 선험적 정보(a priori information)를 사용할 수 있도록 요구합니다 [98]. 가장 간단하고 유용한 모델은 각 프로세스가 필요할 수 있는 각 유형의 최대 자원 수를 미리 선언하도록 요구합니다 [98]. 교착 상태 회피 알고리즘은 자원 할당 상태를 동적으로 검사하여 순환 대기 조건이 발생하지 않도록 보장합니다 [98]. 자원 할당 상태는 사용 가능한 자원 및 할당된 자원 수, 그리고 프로세스의 최대 요구량으로 정의됩니다 [98].
**안전 상태 (Safe State)**스레드가 사용 가능한 자원을 요청할 때, 시스템은 즉시 할당이 시스템을 안전 상태(safe state)로 유지하는지 결정해야 합니다 [99]. 시스템은 시스템의 모든 스레드 <T1, T2, ..., Tn>에 대한 순서가 존재하여, 각 Ti에 대해 Ti가 여전히 요청할 수 있는 자원을 현재 사용 가능한 자원 + i보다 작은 모든 Tj가 보유한 자원으로 충족할 수 있다면 안전 상태입니다 [99]. 즉: Ti의 자원 요구가 즉시 사용 가능하지 않다면, Ti는 모든 Tj가 완료될 때까지 기다릴 수 있습니다 [99]. Tj가 완료되면 Ti는 필요한 자원을 얻고, 실행하고, 할당된 자원을 반환하고, 종료할 수 있습니다 [99]. Ti가 종료되면 Ti+1은 필요한 자원을 얻고 진행할 수 있습니다 [99].
안전 상태 예시 [100] 자원 12개, 스레드 3개 (T0, T1, T2)인 시스템 [100]. 시간 t0에서의 상태: (표 제시: Max Needs, Allocation, Available) [100]. Need = Max - Allocation으로 계산됩니다. 예를 들어 T0의 Need = Max(10) - Allocation(5) = 5. 시간 t0에서 시스템은 안전 상태입니다 [100]. 순서 <T1, T0, T2>가 안전 조건을 만족합니다 [100]. (예: T1은 Need가 2이고 Available이 3이므로 완료 가능 -> Work=3+Allocation(T1)=3+2=5. T0은 Need가 5이고 Work가 5이므로 완료 가능 -> Work=5+Allocation(T0)=5+5=10. T2는 Need가 7이고 Work가 10이므로 완료 가능). 만약 스레드 T2가 자원 1개를 더 요청하고 할당받으면 (예시 표에서 T2 Allocation 2+1=3, Available 3-1=2가 되면), 시스템은 안전 상태에서 불안전 상태(unsafe state)로 갈 수 있습니다 [100].
기본 사실: 시스템이 안전 상태이면 교착 상태가 없습니다 [101]. 시스템이 불안전 상태이면 교착 상태 가능성이 있습니다 [101]. 회피(Avoidance)는 시스템이 절대로 불안전 상태에 들어가지 않도록 보장하는 것입니다 [101].
회피 알고리즘 (Avoidance Algorithms) [102]
•
자원 유형당 인스턴스가 하나인 경우: 자원 할당 그래프를 사용합니다 [102].
•
자원 유형당 인스턴스가 여러 개인 경우: **은행가 알고리즘(Banker’s Algorithm)**을 사용합니다 [102].
자원 할당 그래프 스키마 (Resource-Allocation Graph Scheme) - 단일 인스턴스 [103, 104]
•
요청 간선(claim edge) Ti ---→ Rj는 프로세스 Ti가 자원 Rj를 요청할 수 있음을 나타내며, 점선으로 표현됩니다 [103].
•
스레드가 자원을 요청할 때 요청 간선은 요청 간선(request edge)으로 변환됩니다 [103].
•
자원이 스레드에 할당될 때 요청 간선은 할당 간선(assignment edge)으로 변환됩니다 [103].
•
스레드가 자원을 해제할 때 할당 간선은 요청 간선(claim edge)으로 다시 변환됩니다 [103].
•
시스템에서 자원은 스레드 Ti가 실행을 시작하기 전에 미리 요청(claimed a priori)되어야 합니다 [103]. 자원 할당 그래프 알고리즘: 스레드 Ti가 자원 Rj를 요청한다고 가정합니다 [104]. 요청은 요청 간선을 할당 간선으로 변환하는 것이 자원 할당 그래프에 사이클을 형성하지 않는 경우에만 허용될 수 있습니다 [104].
은행가 알고리즘 (Banker’s Algorithm) - 여러 인스턴스 [105, 106]
•
각 스레드는 최대 사용량을 미리 요청해야 합니다 [105].
•
스레드가 자원을 요청할 때 대기해야 할 수 있습니다 [105].
•
스레드가 모든 자원을 얻으면 유한한 시간 안에 자원을 반환해야 합니다 [105].
은행가 알고리즘의 데이터 구조 [107, 108]: n = 프로세스 수, m = 자원 유형 수.
•
Available: 길이가 m인 벡터. Available[j] = k이면 자원 유형 Rj의 인스턴스가 k개 사용 가능합니다 [107].
•
Max: n x m 행렬. Max[i, j] = k이면 프로세스 Pi는 자원 유형 Rj의 인스턴스를 최대 k개 요청할 수 있습니다 [107].
•
Allocation: n x m 행렬. Allocation[i, j] = k이면 Pi에게 현재 Rj 인스턴스 k개가 할당되었습니다 [107].
•
Need: n x m 행렬. Need[i, j] = k이면 Pi는 작업을 완료하기 위해 Rj 인스턴스 k개가 더 필요할 수 있습니다 [107]. Need [i, j] = Max[i, j] – Allocation [i, j]입니다 [107].
안전성 알고리즘 (Safety Algorithm) [108, 109] 시스템이 안전 상태인지 확인하는 알고리즘입니다.
1.
길이가 m인 Work 벡터와 길이가 n인 Finish 벡터를 초기화합니다. Work = Available [108]. Finish [i] = false for i = 0, 1, ..., n- 1 [108]. (단, Allocation_i가 0이 아닌 경우 Finish[i]는 false, 0인 경우 true로 초기화해야 더 정확합니다. 이는 탐지 알고리즘의 초기화와 일관성을 유지하기 위함이며, 안전성 알고리즘의 목적은 '모든' 프로세스가 완료 가능한지 보는 것이므로 초기 Allocation이 0이 아닌 프로세스만 고려 대상입니다).
2.
다음 두 조건을 모두 만족하는 i를 찾습니다: (a) Finish [i] == false, (b) Needi  Work [108]. 그런 i가 없으면 4단계로 이동합니다 [108].
3.
Work = Work + Allocationi (프로세스 i가 완료되고 자원을 반환했다고 가정) [109]. Finish[i] = true [109]. 2단계로 이동합니다 [109].
4.
모든 i에 대해 Finish [i] == true이면 시스템은 안전 상태입니다 [109]. 그렇지 않으면 불안전 상태입니다. 예시 테이블과 함께 안전성 알고리즘 실행 과정을 보여줍니다 [109, 110]. 순서 <T1, T3, T4, T2, T0>이 안전 기준을 만족함을 보여줍니다 [110, 111].
프로세스 Pi에 대한 자원 요청 알고리즘 (Resource-Request Algorithm for Process Pi) [112]Requesti = 프로세스 Ti의 요청 벡터. Requesti [j] = k이면 프로세스 Ti는 자원 유형 Rj의 k개 인스턴스를 원합니다 [112].
1.
Requesti  Needi이면 2단계로 이동합니다. 그렇지 않으면 프로세스가 최대 요청량을 초과했으므로 오류 상태를 발생시킵니다 [112].
2.
Requesti  Available이면 3단계로 이동합니다. 그렇지 않으면 자원이 사용 가능하지 않으므로 Ti는 대기해야 합니다 [112].
3.
요청된 자원을 Ti에게 할당했다고 가정하고 다음과 같이 상태를 수정합니다 [112]: Available = Available – Requesti;, Allocationi= Allocationi + Requesti;, Needi = Needi – Requesti; [112].
◦
수정된 상태가 안전한지 안전성 알고리즘으로 검사합니다 [112].
◦
안전하면 자원이 Ti에 할당됩니다 [112].
◦
안전하지 않으면 Ti는 대기해야 하고, 이전 자원 할당 상태는 복원됩니다 [112]. 예시: T1의 요청 (1,0,2)에 대해 검사합니다 [113, 114]. (1,0,2) ≤ (3,3,2) 이므로 true (Available보다 작거나 같음) [113]. 가상 할당 후 안전성 알고리즘을 실행하면 순서 <T1, T3, T4, T0, T2>가 안전 기준을 만족하므로 요청이 허용됩니다 [114]. T4의 요청 (3,3,0) 또는 T0의 요청 (0,2,0)은 허용될 수 있는지 질문합니다 [114]. (T4의 Need는 (4,3,1)이고, Request (3,3,0)는 Need보다 작거나 같으므로 1단계 통과. Request (3,3,0)는 Available (3,3,2)보다 작거나 같으므로 2단계 통과. 가상 할당 후 Available은 (0,0,2), T4의 Allocation은 (4,3,1), Need는 (1,0,1)이 됩니다. 이 상태에서 안전성 검사를 수행합니다. T0~T3 모두 Request > Available 이므로 진행 불가. T4도 Need (1,0,1) > Available (0,0,2) 이므로 진행 불가. 따라서 불안전 상태. 요청 거부. T0의 Need는 (7,4,3)이고, Request (0,2,0)는 Need보다 작거나 같으므로 1단계 통과. Request (0,2,0)는 Available (3,3,2)보다 작거나 같으므로 2단계 통과. 가상 할당 후 Available은 (3,1,2), T0의 Allocation은 (0,3,0), Need는 (7,1,3)이 됩니다. 이 상태에서 안전성 검사를 수행합니다...).
**교착 상태 탐지 (Deadlock Detection)**시스템이 교착 상태에 들어가도록 허용합니다 [115]. 시스템이 교착 상태 예방 또는 회피 알고리즘을 사용하지 않는 경우 사용됩니다 [115]. 탐지 알고리즘과 복구 스키마가 필요합니다 [115].
자원 유형당 인스턴스가 하나인 경우
•
**대기 그래프(wait-for graph)**를 유지 관리합니다 [115]. 노드는 스레드입니다 [115]. Ti → Tj는 Ti가 Tj를 대기하고 있음을 나타냅니다 [115].
•
주기적으로 그래프에서 사이클을 검색하는 알고리즘을 호출합니다 [115]. 사이클이 있으면 교착 상태가 존재합니다 [115]. 그래프에서 사이클을 탐지하는 알고리즘은 그래프 꼭짓점 수 n에 대해 O(n^2)의 연산이 필요합니다 [115]. 자원 할당 그래프와 해당 대기 그래프 그림 [115, 116].
자원 유형당 여러 인스턴스가 있는 경우 [117]
•
Available: 각 유형의 사용 가능한 자원 수를 나타내는 길이가 m인 벡터입니다 [117].
•
Allocation: 각 프로세스에 현재 할당된 각 유형의 자원 수를 정의하는 n x m 행렬입니다 [117].
•
Request: 각 프로세스의 현재 요청을 나타내는 n x m 행렬입니다 [117]. Request [i][j] = k이면 스레드 Ti는 자원 유형 Rj의 k개 인스턴스를 더 요청하고 있습니다 [117]. 예시 데이터 구조 [117].
탐지 알고리즘 (Detection Algorithm) [118] 시스템이 교착 상태인지 탐지합니다.
1.
길이가 m인 Work 벡터와 길이가 n인 Finish 벡터를 초기화합니다 [118]. (a) Work = Available [118]. (b) i = 0, 1, ..., n-1에 대해, Allocationi ≠ 0이면 Finish[i] = false로 설정하고, 그렇지 않으면 Finish[i] = true로 설정합니다 [118]. (Allocation이 0이 아닌 프로세스만 교착 상태 후보입니다).
2.
다음 두 조건을 모두 만족하는 인덱스 i를 찾습니다: (a) Finish[i] == false, (b) Requesti  Work [118]. 그런 i가 없으면 4단계로 이동합니다 [118].
3.
Work = Work + Allocationi (프로세스 i가 완료되고 자원을 반환했다고 가정) [118]. Finish[i] = true [118]. 2단계로 이동합니다 [118].
4.
일부 i (0 ≤ i < n)에 대해 Finish[i] == false이면 시스템은 교착 상태에 있습니다 [118]. 더욱이, Finish[i] == false이면 Ti는 교착 상태에 빠져 있습니다 [118]. 이 알고리즘은 시스템이 교착 상태인지 탐지하기 위해 O(m x n^2) 연산이 필요합니다 [118]. 예시 데이터와 함께 탐지 알고리즘 실행 과정을 보여줍니다 [119]. 순서 <T0, T2, T3, T1, T4>는 모든 i에 대해 Finish[i] = true를 초래하므로 교착 상태가 아님을 보여줍니다 [119]. T2가 자원 C의 추가 인스턴스 1개를 요청하는 예시(Request 행렬 수정)를 보여줍니다 [120]. 이 상태에서 T0의 자원은 회수할 수 있지만, 다른 스레드의 요청을 충족할 자원이 부족하여 교착 상태가 존재하며, T1, T2, T3, T4 스레드로 구성됩니다 [120].
**탐지 알고리즘 사용 (Detection-Algorithm Usage)**언제, 얼마나 자주 알고리즘을 호출할지는 다음에 따라 다릅니다 [121]:
•
교착 상태가 얼마나 자주 발생할 가능성이 있는지? [121].
•
얼마나 많은 프로세스를 롤백해야 하는지? [121]. 각 독립된 사이클마다 하나씩입니다 [121]. 탐지 알고리즘이 임의로 호출되면 자원 그래프에 많은 사이클이 있을 수 있어, 많은 교착 상태 프로세스 중 어떤 프로세스가 교착 상태를 "유발"했는지 알 수 없을 수 있습니다 [121].
교착 상태로부터의 복구 (Recovery from Deadlock)
•
프로세스 종료 (Process Termination): 모든 교착 상태 프로세스를 중단(abort)하거나 [122], 교착 상태 사이클이 제거될 때까지 한 번에 하나씩 프로세스를 중단합니다 [122]. 어떤 순서로 중단할 프로세스를 선택해야 할까요? [122]. 기준: 1. 프로세스의 우선순위, 2. 프로세스가 계산한 시간 및 완료까지 남은 시간, 3. 프로세스가 사용한 자원, 4. 프로세스가 완료하는 데 필요한 자원, 5. 종료해야 할 프로세스 수, 6. 프로세스가 대화형인지 배치 처리인지 [122].
•
자원 선점 (Resource Preemption): 희생자(victim) 선택 - 비용 최소화 [122]. 롤백(Rollback) - 일부 안전 상태로 돌아가서 해당 상태부터 프로세스를 다시 시작합니다 [122]. 굶주림(Starvation) - 동일한 프로세스가 항상 희생자로 선택될 수 있으므로, 비용 요인에 롤백 횟수를 포함합니다 [122].
제 9장 주 메모리 (Main Memory)
개요본 장에서는 메모리 관리의 배경 [123], 연속 메모리 할당(Contiguous Memory Allocation) [123], 페이징(Paging) [123], 페이지 테이블 구조(Structure of the Page Table) [123], 그리고 스와핑(Swapping) [123]을 다룹니다.
배경프로그램이 실행되려면 디스크에서 메모리로 가져와 프로세스 내에 배치되어야 합니다 [124]. 주 메모리와 레지스터만이 CPU가 직접 접근할 수 있는 저장소입니다 [124]. 메모리 단위는 주소 + 읽기 요청 또는 주소 + 데이터 + 쓰기 요청의 스트림만 봅니다 [124]. 레지스터 접근은 CPU 클럭 한 번(또는 그 이하)에 이루어집니다 [124]. 주 메모리는 많은 클럭 사이클이 소요될 수 있어 정지(stall)를 유발합니다 [124]. 캐시는 주 메모리와 CPU 레지스터 사이에 위치합니다 [124]. 올바른 작동을 보장하기 위해 메모리 보호가 필요합니다 [124].
**보호 (Protection)**프로세스가 자신의 주소 공간 내의 주소만 접근할 수 있도록 보장해야 합니다 [125]. 이를 위해 베이스(base) 레지스터와 리밋(limit) 레지스터 쌍을 사용하여 프로세스의 논리 주소 공간을 정의할 수 있습니다 [125].
**하드웨어 주소 보호 (Hardware Address Protection)**CPU는 사용자 모드에서 생성된 모든 메모리 접근이 해당 사용자의 베이스 및 리밋 레지스터 범위 내에 있는지 확인해야 합니다 [125]. 베이스 및 리밋 레지스터를 로드하는 명령어는 특권(privileged) 명령어입니다 [125]. (사용자 프로세스는 이 레지스터 값을 변경할 수 없습니다).
**주소 바인딩 (Address Binding)**디스크에 있는 프로그램은 실행을 위해 메모리로 가져와 입력 큐를 형성합니다 [126]. 지원이 없다면, 주소 0000에 로드되어야 합니다 [126]. 첫 번째 사용자 프로세스의 물리 주소가 항상 0000에 있는 것은 불편합니다 [126]. 어떻게 다를 수 있을까요? [126]. 프로그램 생애의 여러 단계에서 주소가 다르게 표현됩니다 [126].
•
소스 코드 주소는 보통 기호적(symbolic)입니다 [126].
•
컴파일된 코드는 재배치 가능 주소(relocatable addresses)에 바인딩됩니다 (예: "이 모듈의 시작 부분에서 14바이트 떨어져") [126].
•
링커 또는 로더가 재배치 가능 주소를 절대 주소(absolute addresses)에 바인딩합니다 (예: 74014) [126]. 각 바인딩은 하나의 주소 공간을 다른 주소 공간으로 매핑합니다 [127].
명령어 및 데이터의 메모리 바인딩 [128] 명령어 및 데이터의 메모리 주소 바인딩은 세 가지 다른 단계에서 발생할 수 있습니다:
•
컴파일 시간 (Compile time): 메모리 위치가 미리 알려진 경우 절대 코드(absolute code)가 생성될 수 있습니다 [128]. 시작 위치가 변경되면 코드를 다시 컴파일해야 합니다 [128].
•
로드 시간 (Load time): 컴파일 시간에 메모리 위치가 알려지지 않은 경우 재배치 가능 코드(relocatable code)를 생성해야 합니다 [128]. 바인딩은 로드 시간에 이루어집니다.
•
실행 시간 (Execution time): 프로세스가 실행 중에 한 메모리 세그먼트에서 다른 세그먼트로 이동될 수 있는 경우 바인딩이 실행 시간까지 지연됩니다 [128]. 주소 매핑을 위한 하드웨어 지원(예: 베이스 및 리밋 레지스터)이 필요합니다 [128].
사용자 프로그램의 다단계 처리 그림 [128]: 소스 파일 -> 컴파일러/어셈블러 -> 목적 파일 -> 링커 -> 실행 파일 -> 로더 -> 메모리.
**논리 주소 공간 대 물리 주소 공간 (Logical vs. Physical Address Space)**별도의 물리 주소 공간에 바인딩되는 논리 주소 공간 개념은 적절한 메모리 관리의 핵심입니다 [129].
•
논리 주소 (Logical address): CPU에 의해 생성됩니다. **가상 주소(virtual address)**라고도 불립니다 [129].
•
물리 주소 (Physical address): 메모리 단위에서 보이는 주소입니다 [129]. 컴파일 시간 및 로드 시간 주소 바인딩 스키마에서는 논리 주소와 물리 주소가 같습니다 [129]. 실행 시간 주소 바인딩 스키마에서는 논리 주소와 물리 주소가 다릅니다 [129]. 논리 주소 공간은 프로그램이 생성하는 모든 논리 주소의 집합입니다 [129]. 물리 주소 공간은 프로그램이 생성하는 모든 물리 주소의 집합입니다 [129].
메모리 관리 장치 (Memory-Management Unit, MMU) 실행 시간에 가상 주소를 물리 주소로 매핑하는 하드웨어 장치입니다 [130]. 본 장의 나머지 부분에서 다룰 다양한 방법이 가능합니다 [130]. 간단한 스키마를 고려합니다 [131]. 이는 베이스 레지스터 스키마의 일반화입니다 [131]. 베이스 레지스터는 이제 **재배치 레지스터(relocation register)**라고 불립니다 [131]. 재배치 레지스터의 값은 사용자 프로세스가 생성한 모든 주소에 메모리로 전송될 때 추가됩니다 [131]. 사용자 프로그램은 논리 주소로 작업하며 실제 물리 주소는 보지 않습니다 [131]. 실행 시간 바인딩은 메모리 위치를 참조할 때 발생합니다 [131].
**동적 로딩 (Dynamic Loading)**프로그램 전체가 실행을 위해 메모리에 있을 필요는 없습니다 [132]. 루틴은 호출될 때까지 로드되지 않습니다 [132]. 더 나은 메모리 공간 활용을 제공하며, 사용되지 않는 루틴은 로드되지 않습니다 [132]. 모든 루틴은 디스크에 재배치 가능한 로드 형식으로 보관됩니다 [132]. 드물게 발생하는 경우를 처리하기 위해 많은 양의 코드가 필요할 때 유용합니다 [132]. 운영체제로부터 특별한 지원은 필요하지 않습니다 [132]. 프로그램 설계를 통해 구현됩니다 [132]. OS는 동적 로딩을 구현하는 라이브러리를 제공하여 도움을 줄 수 있습니다 [132].
**동적 연결 (Dynamic Linking)**정적 연결(Static linking): 시스템 라이브러리와 프로그램 코드가 로더에 의해 바이너리 프로그램 이미지로 결합됩니다 [133]. 동적 연결(Dynamic linking): 연결이 실행 시간까지 연기됩니다 [133]. 적절한 메모리 상주 라이브러리 루틴을 찾기 위해 작은 코드 조각인 **스텁(stub)**이 사용됩니다 [133]. 스텁은 자신을 루틴의 주소로 대체하고 루틴을 실행합니다 [133]. 운영체제는 루틴이 프로세스의 메모리 주소 공간에 있는지 확인합니다 [133]. 주소 공간에 없으면 주소 공간에 추가합니다 [133]. 동적 연결은 라이브러리에 특히 유용합니다 [133]. 시스템은 **공유 라이브러리(shared libraries)**로도 알려져 있습니다 [133]. 시스템 라이브러리 패치 적용에 대한 적용 가능성을 고려할 수 있으며, 버전 관리가 필요할 수 있습니다 [133].
**연속 할당 (Contiguous Allocation)**주 메모리는 OS 및 사용자 프로세스 모두를 지원해야 합니다 [134]. 제한된 자원이므로 효율적으로 할당해야 합니다 [134]. 연속 할당은 초기 방법 중 하나입니다 [134]. 주 메모리는 일반적으로 두 부분으로 나뉩니다 [134].
•
상주 운영체제(Resident operating system): 일반적으로 인터럽트 벡터와 함께 저위 메모리(low memory)에 위치합니다 [134].
•
사용자 프로세스: 고위 메모리(high memory)에 위치합니다 [134]. 각 프로세스는 단일의 연속된 메모리 섹션에 포함됩니다 [134].
**연속 할당 (계속)**재배치 레지스터는 사용자 프로세스를 서로로부터, 그리고 운영체제 코드 및 데이터를 변경하는 것으로부터 보호하는 데 사용됩니다 [135]. 베이스 레지스터는 가장 작은 물리 주소 값을 포함합니다 [135]. 리밋 레지스터는 논리 주소의 범위를 포함하며, 각 논리 주소는 리밋 레지스터 값보다 작아야 합니다 [135]. MMU는 논리 주소를 동적으로 매핑합니다 [135]. 이를 통해 커널 코드가 일시적이고 커널 크기가 변경되는 등의 작업이 가능해집니다 [135]. 재배치 및 리밋 레지스터에 대한 하드웨어 지원 그림 [136].
**가변 분할 (Variable Partition)**다중 분할 할당(Multiple-partition allocation) 방식입니다 [136]. 다중 프로그래밍 정도는 분할 수에 의해 제한됩니다 [136]. 효율성을 위해 가변 분할 크기(주어진 프로세스의 요구에 맞게 크기가 조정됨)를 사용합니다 [136]. 홀(Hole): 사용 가능한 메모리 블록 [136]. 다양한 크기의 홀이 메모리 전체에 흩어져 있습니다 [136]. 프로세스가 도착하면 수용할 만큼 충분히 큰 홀에서 메모리가 할당됩니다 [136]. 프로세스가 종료하면 해당 분할을 해제하고 인접한 빈 분할은 병합됩니다 [136]. 운영체제는 다음 정보를 유지 관리합니다: a) 할당된 분할, b) 빈 분할(홀) [137].
**동적 저장소 할당 문제 (Dynamic Storage-Allocation Problem)**빈 홀 목록에서 크기 n의 요청을 어떻게 만족시킬까요? [138].
•
First-fit: 충분히 큰 첫 번째 홀을 할당합니다 [138].
•
Best-fit: 충분히 큰 가장 작은 홀을 할당합니다. 크기 순으로 정렬되어 있지 않으면 전체 목록을 검색해야 합니다 [138]. 가장 작은 남은 홀을 생성합니다 [138].
•
Worst-fit: 가장 큰 홀을 할당합니다. 역시 전체 목록을 검색해야 합니다 [138]. 가장 큰 남은 홀을 생성합니다 [138]. First-fit과 Best-fit은 속도 및 저장 공간 활용 측면에서 Worst-fit보다 우수합니다 [138].
단편화 (Fragmentation)
•
외부 단편화 (External Fragmentation): 요청을 만족시킬 수 있는 총 메모리 공간이 존재하지만, 그것이 연속적이지 않습니다 [138].
•
내부 단편화 (Internal Fragmentation): 할당된 메모리가 요청된 메모리보다 약간 더 클 수 있습니다 [138]. 이 크기 차이는 분할 내부의 메모리이지만 사용되지 않습니다 [138]. First-fit 분석 결과, N개의 블록이 할당되면 0.5 N개의 블록이 단편화로 손실됩니다 [139]. 1/3이 사용 불가능할 수 있습니다 (50% 규칙) [139].
**단편화 (계속)**압축(compaction)을 통해 외부 단편화를 줄입니다 [139]. 메모리 내용을 재배열하여 모든 빈 메모리를 하나의 큰 블록으로 모읍니다 [139]. 압축은 재배치가 동적이고 실행 시간에 이루어지는 경우에만 가능합니다 [139]. I/O 문제입니다 [139]. I/O에 관여하는 작업은 메모리에 고정하고 [139], OS 버퍼로만 I/O를 수행합니다 [139]. 백킹 저장소도 동일한 단편화 문제를 가집니다 [140].
페이징 (Paging) [141] 프로세스의 물리 주소 공간은 비연속적일 수 있습니다 [141]. 프로세스는 사용 가능한 물리 메모리가 있을 때마다 할당받습니다 [141]. 외부 단편화를 방지합니다 [142]. 가변 크기 메모리 덩어리 문제를 피합니다 [142]. 물리 메모리를 고정 크기 블록인 프레임(frames)으로 나눕니다 [142]. 크기는 2의 거듭제곱이며, 512 바이트에서 16 MB 사이입니다 [142]. 논리 메모리를 동일한 크기의 블록인 페이지(pages)로 나눕니다 [142]. 모든 빈 프레임을 추적합니다 [142]. N 페이지 크기의 프로그램을 실행하려면 N개의 빈 프레임을 찾아 프로그램을 로드해야 합니다 [142]. 논리 주소를 물리 주소로 변환하기 위해 **페이지 테이블(page table)**을 설정합니다 [142]. 백킹 저장소도 페이지로 분할됩니다 [142]. 여전히 내부 단편화는 발생합니다 [142]. (할당된 마지막 페이지의 일부 공간은 사용되지 않을 수 있기 때문입니다).
주소 변환 스키마 (Address Translation Scheme) [143] CPU가 생성한 주소는 다음으로 나뉩니다:
•
페이지 번호 (p): 페이지 테이블의 인덱스로 사용되며, 물리 메모리에서 각 페이지의 베이스 주소를 포함합니다 [143].
•
페이지 오프셋 (d): 베이스 주소와 결합되어 메모리 단위로 전송되는 물리 메모리 주소를 정의합니다 [143]. 주어진 논리 주소 공간 2^m 및 페이지 크기 2^n에 대해, 페이지 번호 p는 m-n 비트, 페이지 오프셋 d는 n 비트입니다 [143]. 그림은 주소 분할을 보여줍니다 [143].
페이징 하드웨어 그림 [144]. 논리 및 물리 메모리의 페이징 모델 그림 [144]. 페이징 예시 (n=2, m=4, 페이지 크기 4 바이트, 물리 메모리 32 바이트/8 페이지) 그림 [144].
내부 단편화 계산 [144] 예시: 페이지 크기 = 2,048 바이트, 프로세스 크기 = 72,766 바이트. 72766 / 2048 = 35 페이지 + 1,086 바이트 [144]. 마지막 페이지에서 내부 단편화는 2,048 - 1,086 = 962 바이트입니다 [144]. 최악의 경우 단편화는 1 프레임 - 1 바이트입니다 [144]. 평균 단편화는 1/2 프레임 크기입니다 [144]. 따라서 작은 프레임 크기가 바람직할까요? [144]. 그러나 각 페이지 테이블 항목은 추적하기 위해 메모리를 차지합니다 [144]. 페이지 크기는 시간이 지남에 따라 커지고 있습니다 [144]. 솔라리스는 두 가지 페이지 크기(8 KB 및 4 MB)를 지원합니다 [144].
빈 프레임 그림 [145]. 할당 전과 후의 빈 프레임 목록을 보여줍니다.
페이지 테이블 구현 (Implementation of Page Table) [145] 페이지 테이블은 주 메모리에 보관됩니다 [145]. 페이지 테이블 베이스 레지스터(PTBR)는 페이지 테이블을 가리킵니다 [145]. 페이지 테이블 길이 레지스터(PTLR)는 페이지 테이블의 크기를 나타냅니다 [145]. 이 스키마에서는 모든 데이터/명령어 접근에 두 번의 메모리 접근이 필요합니다 [145]. 한 번은 페이지 테이블을 위한 접근이고, 한 번은 데이터/명령어를 위한 접근입니다 [145]. 두 번의 메모리 접근 문제는 **변환 색인 버퍼(translation look-aside buffers, TLBs)**라는 특별한 고속 탐색 하드웨어 캐시(연관 메모리라고도 함)를 사용하여 해결할 수 있습니다 [145].
변환 색인 버퍼 (Translation Look-Aside Buffer, TLB) [146] 고속 탐색 하드웨어 캐시입니다 [145]. 일부 TLB는 각 TLB 항목에 주소 공간 식별자(ASIDs)를 저장하여 각 프로세스에 대한 주소 공간 보호를 제공합니다 [146]. 그렇지 않으면 컨텍스트 스위치 시마다 플러시해야 합니다 [146]. TLB는 일반적으로 작습니다 (64에서 1,024 항목) [146]. TLB 미스(miss) 시, 다음 번 빠른 접근을 위해 값이 TLB에 로드됩니다 [146]. 대체 정책을 고려해야 합니다 [146]. 일부 항목은 영구적인 빠른 접근을 위해 고정(wired down)될 수 있습니다 [146].
TLB가 포함된 페이징 하드웨어 그림 [146].
유효 접근 시간 (Effective Access Time, EAT) [147, 148] **히트율(Hit ratio)**은 페이지 번호가 TLB에서 발견되는 비율입니다 [148]. 히트율 80%는 시간의 80% 동안 TLB에서 원하는 페이지 번호를 찾는 것을 의미합니다 [147]. 메모리 접근에 10 나노초가 걸린다고 가정합니다 [147].
•
TLB에서 원하는 페이지를 찾으면 매핑된 메모리 접근은 10 ns가 걸립니다 [147]. (이것은 TLB 접근 시간 + 메모리 접근 시간을 합한 시간으로 해석하는 것이 자연스럽습니다).
•
그렇지 않으면 페이지 테이블 접근(메모리)과 데이터 접근(메모리) 두 번의 메모리 접근이 필요하므로 20 ns가 걸립니다 [147]. (이것은 페이지 테이블 접근 10ns + 데이터 접근 10ns의 합으로 해석하는 것이 자연스럽습니다).유효 접근 시간 (EAT) 공식: EAT = 히트율 * (TLB 히트 시 시간) + (1 - 히트율) * (TLB 미스 시 시간) [147].
•
80% 히트율 예시: EAT = 0.80 * 10 + 0.20 * 20 = 8 + 4 = 12 나노초 [147]. 이는 접근 시간에 20% 느려짐을 의미합니다 [147].
•
더 현실적인 99% 히트율 고려: EAT = 0.99 * 10 + 0.01 * 20 = 9.9 + 0.2 = 10.1 나노초 [148]. 이는 접근 시간에 1% 느려짐만을 의미합니다 [148].
메모리 보호 (Memory Protection) [149] 메모리 보호는 각 프레임에 보호 비트(protection bit)를 연결하여 읽기 전용 또는 읽기-쓰기 접근이 허용되는지 여부를 나타내는 방식으로 구현됩니다 [149]. 페이지 실행 전용 등 더 많은 비트를 추가할 수도 있습니다 [149]. **유효-무효 비트(Valid-invalid bit)**는 페이지 테이블의 각 항목에 첨부됩니다 [149]:
•
"유효(valid)"는 연결된 페이지가 프로세스의 논리 주소 공간에 있으며 유효한 페이지임을 나타냅니다 [149].
•
"무효(invalid)"는 페이지가 프로세스의 논리 주소 공간에 없음을 나타냅니다 [149]. 또는 페이지 테이블 길이 레지스터(PTLR)를 사용할 수도 있습니다 [149]. 어떤 위반이든 커널로 트랩(trap)을 유발합니다 [149]. 페이지 테이블의 유효(v) 또는 무효(i) 비트 그림 [149].
공유 페이지 (Shared Pages) [150]
•
공유 코드 (Shared code): 읽기 전용(reentrant) 코드의 한 복사본이 프로세스 간에 공유됩니다 (예: 텍스트 편집기, 컴파일러, 창 시스템) [150]. 이는 동일한 프로세스 공간을 공유하는 여러 스레드와 유사합니다 [150]. 읽기-쓰기 페이지 공유가 허용된다면 프로세스 간 통신에도 유용합니다 [150].
•
개인 코드 및 데이터 (Private code and data): 각 프로세스는 코드 및 데이터의 별도 복사본을 유지합니다 [150]. 개인 코드 및 데이터 페이지는 논리 주소 공간 어디에나 나타날 수 있습니다 [150]. 공유 페이지 예시 그림 [150].
페이지 테이블 구조 (Structure of the Page Table) [151] 단순한 방법으로는 페이징을 위한 메모리 구조가 매우 커질 수 있습니다 [151]. 현대 컴퓨터와 같이 32비트 논리 주소 공간을 고려합니다 [151]. 페이지 크기가 4 KB (2^12)인 경우 [151], 페이지 테이블은 100만(2^32 / 2^12 = 2^20) 항목을 가질 것입니다 [151]. 각 항목이 4 바이트인 경우, 각 프로세스는 페이지 테이블만을 위해 4 MB의 물리 주소 공간을 필요로 합니다 [151]. 이를 주 메모리에 연속적으로 할당하고 싶지 않습니다 [151]. 간단한 해결책은 페이지 테이블을 더 작은 단위로 나누는 것입니다 [151].
•
계층적 페이징 (Hierarchical Paging) [151]
•
해시 페이지 테이블 (Hashed Page Tables) [151]
•
역 페이지 테이블 (Inverted Page Tables) [151]
계층적 페이지 테이블 (Hierarchical Page Tables) [151, 152] 논리 주소 공간을 여러 페이지 테이블로 나눕니다 [151]. 간단한 기술은 **두 수준 페이지 테이블 (two-level page table)**입니다 [151]. 그런 다음 페이지 테이블을 페이징합니다 [151].
두 수준 페이징 예시 (32비트 머신, 1K 페이지 크기) [152] 논리 주소는 다음으로 나뉩니다:
•
페이지 번호 (22 비트) [152]
•
페이지 오프셋 (10 비트) [152] 페이지 테이블이 페이징되므로, 페이지 번호는 다시 다음으로 나뉩니다:
•
10 비트 페이지 번호 (p1) [152]
•
12 비트 페이지 오프셋 (p2) [152] 따라서 논리 주소는 다음과 같습니다: 페이지 번호 | 페이지 오프셋 -> p1 | p2 | d [152]. 여기서 p1은 외부 페이지 테이블의 인덱스이고, p2는 내부 페이지 테이블의 페이지 내 변위(displacement)입니다 [152]. **전방 매핑 페이지 테이블(forward-mapped page table)**로 알려져 있습니다 [152]. 주소 변환 스키마 그림 [153].
64비트 논리 주소 공간 [153] 두 수준 페이징 스키마도 충분하지 않습니다 [153]. 페이지 크기가 4 KB (2^12)인 경우 [153], 페이지 테이블은 2^52 항목을 가집니다 [153]. 두 수준 스키마에서 내부 페이지 테이블은 2^10 항목 (항목 크기 4 바이트)일 수 있습니다 [153]. 주소는 p1 (42 비트) | p2 (10 비트) | d (12 비트) 와 같을 것입니다 [153]. 외부 페이지 테이블은 2^42 항목 또는 2^44 바이트입니다 [153]. 해결책 중 하나는 두 번째 외부 페이지 테이블을 추가하는 것입니다 [153]. 그러나 이 예시에서는 두 번째 외부 페이지 테이블도 여전히 2^34 바이트 크기입니다 [153]. 그리고 하나의 물리 메모리 위치에 접근하기 위해 최대 4번의 메모리 접근이 필요할 수 있습니다 [153]. 세 수준 페이징 스키마 그림 [154].
해시 페이지 테이블 (Hashed Page Tables) [154, 155] 32 비트보다 큰 주소 공간에서 흔합니다 [154]. 가상 페이지 번호는 페이지 테이블로 해시됩니다 [154]. 이 페이지 테이블은 동일한 위치로 해시되는 요소들의 체인(chain)을 포함합니다 [154]. 각 요소는 (1) 가상 페이지 번호, (2) 매핑된 페이지 프레임 값, (3) 다음 요소에 대한 포인터를 포함합니다 [154]. 일치하는 항목을 찾기 위해 이 체인에서 가상 페이지 번호를 비교합니다 [154]. 일치하는 항목이 발견되면 해당 물리 프레임이 추출됩니다 [154]. 64 비트 주소 변형은 클러스터 페이지 테이블(clustered page tables)입니다 [155]. 해시와 유사하지만 각 항목은 1개가 아닌 여러 페이지(예: 16개)를 참조합니다 [155]. 희소한 주소 공간(메모리 참조가 비연속적이고 흩어져 있는 경우)에 특히 유용합니다 [155]. 해시 페이지 테이블 그림 [155].
역 페이지 테이블 (Inverted Page Table) [156] 각 프로세스가 페이지 테이블을 가지고 모든 가능한 논리 페이지를 추적하는 대신, 모든 물리 페이지를 추적합니다 [156]. 메모리의 실제 페이지 하나당 하나의 항목이 있습니다 [156]. 항목은 해당 실제 메모리 위치에 저장된 페이지의 가상 주소와 해당 페이지를 소유한 프로세스에 대한 정보를 포함합니다 [156]. 페이지 테이블을 저장하는 데 필요한 메모리는 감소하지만, 페이지 참조 발생 시 테이블을 검색하는 데 필요한 시간은 증가합니다 [156]. 검색을 하나 또는 최대 몇 개의 페이지 테이블 항목으로 제한하기 위해 해시 테이블을 사용합니다 [156]. TLB는 접근 속도를 높일 수 있습니다 [156]. 하지만 공유 메모리는 어떻게 구현할까요? [156]. 가상 주소에서 공유 물리 주소로의 하나의 매핑이 필요합니다 [156]. 역 페이지 테이블 아키텍처 그림 [156].
스와핑 (Swapping) [157] 프로세스는 일시적으로 메모리에서 백킹 저장소(backing store)로 스왑 아웃(swapped temporarily out)되었다가, 계속 실행하기 위해 다시 메모리로 스왑 인(brought back into memory)될 수 있습니다 [157]. 프로세스의 총 물리 메모리 공간이 물리 메모리 크기를 초과할 수 있습니다 [157].
•
백킹 저장소 (Backing store): 모든 사용자의 모든 메모리 이미지 복사본을 수용할 만큼 충분히 큰 빠른 디스크입니다 [157]. 이러한 메모리 이미지에 대한 직접 접근을 제공해야 합니다 [157].
•
롤 아웃, 롤 인 (Roll out, roll in): 우선순위 기반 스케줄링 알고리즘에 사용되는 스와핑 변형입니다 [157]. 우선순위가 낮은 프로세스가 스왑 아웃되어 우선순위가 높은 프로세스가 로드되어 실행될 수 있도록 합니다 [157].스와핑 시간의 대부분은 전송 시간입니다 [157]. 총 전송 시간은 스왑된 메모리 양에 직접 비례합니다 [157]. 시스템은 디스크에 메모리 이미지를 가진 실행 준비 상태 프로세스의 준비 큐를 유지 관리합니다 [158].
스와핑 (계속) [158] 스왑 아웃된 프로세스가 동일한 물리 주소로 스왑 인해야 할까요? [158]. 주소 바인딩 방법에 따라 다릅니다 [158]. 또한 프로세스 메모리 공간에 대한 보류 중인 I/O도 고려해야 합니다 [158]. 많은 시스템(예: UNIX, Linux, Windows)에서 수정된 버전의 스와핑이 사용됩니다 [158]. 스와핑은 일반적으로 비활성화되어 있습니다 [158]. 메모리 할당량이 임계값을 초과하면 시작되고, 메모리 수요가 임계값 이하로 감소하면 다시 비활성화됩니다 [158].
스와핑의 개략도 그림 [159]. 페이징과 함께하는 스와핑 그림 [159].
제 5장 CPU 스케줄링 (CPU Scheduling)
기본 개념 (Basic Concepts) [160] 프로세스 실행은 CPU 실행과 I/O 대기 사이의 사이클로 구성됩니다 [160]. 멀티 프로그래밍을 통해 최대 CPU 활용도를 얻을 수 있습니다 [160]. CPU-I/O 버스트 사이클 (CPU-I/O Burst Cycle): 프로세스 실행은 CPU 실행 버스트와 I/O 대기 버스트의 사이클로 구성됩니다 [160]. CPU 버스트 다음에 I/O 버스트가 옵니다 [160]. CPU 버스트 분포가 주요 관심사입니다 [160]. CPU 버스트 시간 히스토그램 그림 [161]: 짧은 버스트의 수가 많고 긴 버스트의 수는 적습니다 [161].
CPU 스케줄러 (CPU Scheduler) [162] CPU 스케줄러는 준비 큐(ready queue)에 있는 프로세스들 중에서 하나를 선택하여 CPU 코어를 할당합니다 [162]. 큐는 다양한 방식으로 정렬될 수 있습니다 [162]. CPU 스케줄링 결정은 프로세스가 다음 상태로 전환될 때 발생할 수 있습니다 [162]:
1.
실행(running)에서 대기(waiting) 상태로 전환 [162].
2.
실행(running)에서 준비(ready) 상태로 전환 [162].
3.
대기(waiting)에서 준비(ready) 상태로 전환 [162].
4.
종료(terminates) [162]. 1번과 4번에서의 스케줄링은 **비선점형(nonpreemptive, cooperative)**입니다 [162]. 그 외 모든 스케줄링은 **선점형(preemptive)**입니다 [162]. 선점형 스케줄링 시 고려사항: 공유 데이터 접근(경합 조건), 커널 모드 중 선점, 중요한 OS 활동 중 인터럽트 발생 [162]. 선점형과 비선점형 스케줄링 그림 [162].
스케줄러 (Scheduler) 종류 [163]
•
장기 스케줄러 (Long-term Scheduler, Job scheduler): 디스크에서 메모리로 작업을 가져와 준비 큐에 넣을 순서를 결정합니다 [163]. 프로세스 수를 제어합니다 [163].
•
단기 스케줄러 (Short-term Scheduler, CPU scheduler): 메모리에 적재된 프로세스 중에서 프로세서(CPU)를 할당하여 실행 상태가 되도록 결정하는 프로세스입니다 [163]. 프로세스에 CPU를 할당합니다 [163].
•
중기 스케줄러 (Medium-term Scheduler, Swapper): 스왑 인(swap-in)과 스왑 아웃(swap-out)을 결정합니다 [163]. 프로세스 수를 제어합니다 [163]. 프로세스 상태 전이 그림 (New, Ready, Running, Waiting, Terminated, Suspend Ready, Suspend Blocked) 및 스케줄러/스왑퍼의 역할 표시 [163].
디스패처 (Dispatcher) [164] 디스패처 모듈은 단기 스케줄러에 의해 선택된 프로세스에게 CPU 제어권을 넘겨줍니다 [164]. 이 과정에는 다음이 포함됩니다:
•
컨텍스트 스위칭 (Switching context) [164].
•
사용자 모드로 전환 (Switching to user mode) [164].
•
사용자 프로그램 내의 적절한 위치로 점프하여 프로그램을 다시 시작 (Jumping to the proper location in the user program to restart that program) [164].디스패치 지연 (Dispatch latency): 디스패처가 한 프로세스를 멈추고 다른 프로세스를 실행하는 데 걸리는 시간입니다 [164].
vmstat 명령 예시 출력 [165]: cs 열은 컨텍스트 스위치 횟수를 나타냅니다 [165]. /proc/[pid]/status 파일 예시 출력 [166]: voluntary_ctxt_switches와 nonvoluntary_ctxt_switches는 자발적/비자발적 컨텍스트 스위치 횟수를 보여줍니다 [166].
스케줄링 기준 (Scheduling Criteria) [167] CPU 스케줄링 알고리즘 최적화를 위한 기준들입니다 [167].
•
CPU 활용률 (CPU utilization): CPU를 가능한 한 바쁘게 유지합니다 (최대화 목표) [167].
•
처리량 (Throughput): 단위 시간당 완료되는 프로세스 수입니다 (최대화 목표) [167].
•
반환 시간 (Turnaround time): 특정 프로세스가 실행되는 데 걸리는 총 시간입니다 (최소화 목표) [167]. (제출 시점부터 완료 시점까지).
•
대기 시간 (Waiting time): 프로세스가 준비 큐에서 대기하는 시간의 합입니다 (최소화 목표) [167].
•
응답 시간 (Response time): 요청이 제출된 시점부터 첫 번째 응답이 생성될 때까지 걸리는 시간입니다 (시간 공유 환경에서 출력까지의 시간이 아님) (최소화 목표) [167]. 프로세스 상태 전이와 스케줄링 기준의 관계 그림 [167].
스케줄링 알고리즘 (이 소스에서는 구체적인 알고리즘은 언급되지 않습니다).
--------------------------------------------------------------------------------
학습 자료 요구사항 명세 제안
운영체제 개념, 특히 동기화, 교착 상태, 메모리 관리, CPU 스케줄링과 같은 복잡한 주제를 학습자들이 확실히 이해하고 효과적으로 활용 및 응용할 수 있도록 돕기 위한 학습 자료 요구사항 명세는 다음과 같이 제안될 수 있습니다.
1.
명확하고 상세한 개념 설명:
◦
핵심 용어 정의: 각 주제별 핵심 용어(예: 경합 조건, 임계 구역, 뮤텍스, 세마포어, 모니터, 교착 상태 조건 4가지, 논리/물리 주소, 페이징, 스와핑, 컨텍스트 스위치, 스케줄링 기준 등)에 대해 정확하고 이해하기 쉬운 정의를 제공해야 합니다.
◦
원리 및 메커니즘 설명: 각 개념이 어떻게 작동하는지(예: 뮤텍스가 상호 배제를 보장하는 원리, 세마포어의 wait/signal 연산, 페이징을 통한 주소 변환 과정, 은행가 알고리즘의 안전성 검사 등) 원리부터 상세하게 설명해야 합니다.
◦
"왜" 그런 개념이 필요한지 설명: 해당 개념이 도입된 배경, 해결하고자 하는 문제, 그리고 그 중요성을 명확히 제시하여 학습 동기를 부여하고 개념의 맥락을 이해하도록 돕습니다 (예: 왜 동시성 문제가 발생하는지, 왜 교착 상태가 문제인지, 왜 메모리 관리가 필요한지).
2.
풍부한 시각 자료:
◦
도식화된 그림: 동기화 문제(생산자-소비자, 읽기-쓰기, 식사하는 철학자), 자원 할당 그래프, 메모리 할당 상태(연속 할당, 페이징), 페이지 테이블 구조, 프로세스 상태 전이 등 복잡한 개념 및 상태 변화를 시각적으로 이해하기 쉽게 도식화된 그림으로 제공해야 합니다.
◦
단계별 그림: 시간의 흐름에 따라 상태가 어떻게 변화하는지(예: 경합 조건 발생 과정, 교착 상태 형성 과정, 페이징 주소 변환 과정) 단계별 그림으로 보여주어 동적인 측면을 이해하도록 돕습니다.
3.
예제 및 코드 활용:
◦
이론 개념 적용 예제: 각 개념이 실제 문제에 어떻게 적용되는지 구체적인 예제(예: 카운터 증가/감소 경합 조건 예제, S1 before S2 문제 해결 예제)를 제시해야 합니다.
◦
실제 코드 예제: C, Java 등 실제 프로그래밍 언어로 구현된 간결하고 핵심적인 코드 예제(예: 뮤텍스/세마포어를 사용한 동기화, 피터슨 알고리즘 구현)를 제공하고, 각 코드 라인이 어떤 의미를 가지는지 상세하게 설명해야 합니다. 실행 결과(올바른 경우와 잘못된 경우 모두)를 보여주어 이론과 실제의 연결고리를 강화합니다.
4.
다양한 관점 및 비교:
◦
대체 방안 비교: 동일한 문제를 해결하는 다양한 접근 방식(예: busy waiting vs blocking, 뮤텍스 vs 이진 세마포어, 연속 할당 vs 페이징, 교착 상태 예방 vs 회피 vs 탐지)의 장단점, 트레이드오프를 명확하게 비교 설명해야 합니다.
◦
구현상의 고려사항: 하드웨어 지원의 역할(예: 원자적 명령어, MMU, TLB), 성능 영향(예: TLB 히트율, 컨텍스트 스위치 비용), 현대 시스템에서의 동작 방식 차이(예: 피터슨 알고리즘과 명령어 재배열) 등 구현상의 실제적인 고려사항을 다룹니다.
5.
흔히 발생하는 문제 및 함정:
◦
잘못된 사용 예시: 동기화 도구(세마포어, 모니터 등)를 잘못 사용했을 때 발생하는 문제점(예: 잘못된 wait/signal 순서로 인한 교착/상호 배제 실패)을 구체적인 예시 코드를 통해 보여주고 설명해야 합니다.
◦
개념 오해 지점: 학습자들이 흔히 오해하거나 혼동하는 개념(예: 교착 상태와 굶주림의 차이, 논리/물리 주소의 차이)을 명확히 짚어주고 올바른 이해를 돕습니다.
6.
단계별 학습 경로 및 응용:
◦
점진적 난이도: 기본적인 개념부터 시작하여 복잡한 주제(예: 다단계 페이지 테이블, 은행가 알고리즘)로 점진적으로 나아가는 구조를 갖추어야 합니다.
◦
응용 및 확장: 고전적인 문제(생산자-소비자 등)를 통해 학습한 개념이 더 복잡한 실제 시스템 문제에 어떻게 응용될 수 있는지 힌트를 제공하거나 간단히 소개합니다.
7.
자기 점검 및 연습 기회:
◦
개념 확인 질문: 각 섹션 또는 주제가 끝날 때마다 주요 개념을 확인하는 간단한 질문을 제공하여 학습자가 스스로 이해도를 점검할 수 있도록 합니다.
◦
다양한 유형의 문제: 개념 이해, 계산, 코드 분석, 오류 찾기 등 다양한 유형의 연습 문제를 제공하여 학습한 내용을 다양한 방식으로 적용하고 응용하는 연습을 할 수 있도록 합니다.
이러한 요구사항을 충족하는 학습 자료는 운영체제의 복잡한 개념을 학습자들이 깊이 있게 이해하고 실제 문제 해결에 적용하는 능력을 기르는 데 크게 기여할 수 있을 것입니다.
--------------------------------------------------------------------------------
연습 문제
학습한 내용을 바탕으로 다음 문제들을 풀어보세요.
문제 1 (개념 이해 - 경합 조건)
다음 C 코드는 두 개의 스레드가 전역 변수 counter를 공유하며 각각 100000번 증가시키는 예제입니다. 이 코드에서 발생할 수 있는 문제점은 무엇이며, 왜 그런 문제가 발생하는지 설명하세요. 예상되는 최종 counter 값과 실제 실행 시 나올 수 있는 값의 차이는 무엇인가요?
#include <stdio.h>
#include <pthread.h>

int counter = 0;

void *increment() {
    for (int i = 0; i < 100000; i++) {
        counter++;
    }
    pthread_exit(0);
}

int main() {
    pthread_t t1, t2;

    pthread_create(&t1, NULL, increment, NULL);
    pthread_create(&t2, NULL, increment, NULL);

    pthread_join(t1, NULL);
    pthread_join(t2, NULL);

    printf("Final counter value: %d\n", counter);

    return 0;
}

해설:
이 코드에서는 두 스레드가 공유 변수 counter에 대해 counter++ 연산을 동시에 수행합니다. counter++ 연산은 원자적 연산이 아니며, 소스 [4]에서 설명된 것처럼 일반적으로 여러 개의 기계어 명령(예: 레지스터에 값 로드, 레지스터 값 증가, 레지스터 값을 메모리에 저장)으로 구성됩니다.
문제점: 이 코드는 **경합 조건(race condition)**을 가지고 있습니다. 두 스레드가 counter 값을 읽고, 증가시키고, 다시 쓰는 과정이 겹칠 수 있습니다. 예를 들어, 한 스레드가 counter 값을 레지스터에 로드한 후 아직 메모리에 저장하기 전에 다른 스레드가 counter 값을 로드하여 증가시키는 경우, 한 번의 증가 연산이 누락될 수 있습니다 (소스 [4]의 예시 참조).
예상되는 최종 값과 실제 값의 차이: 각 스레드는 counter를 100000번 증가시키므로, 두 스레드가 정상적으로 모든 연산을 완료하면 예상되는 최종 counter 값은 200000이어야 합니다. 그러나 경합 조건으로 인해 증가 연산이 누락될 수 있으므로, 실제 실행 시 출력되는 counter 값은 200000보다 작을 수 있으며, 실행할 때마다 다른 값이 나올 수 있습니다. 소스 [6]의 예시에서 10000번 증가/감소 시 최종 값이 예상과 다르게 나온 것을 볼 수 있습니다.
문제 2 (개념 이해 - 교착 상태 특성)
교착 상태가 발생하기 위해 동시에 만족해야 하는 네 가지 필수 조건이 있습니다. 소스 [90]에 따르면 이 네 가지 조건은 무엇인가요? 다음 보기 중 이 네 가지 필수 조건에 포함되지 않는 것은 무엇인가요?
보기: a) 상호 배제 (Mutual exclusion) b) 점유와 대기 (Hold and wait) c) 비선점 (No preemption) d) 우선순위 역전 (Priority inversion) e) 순환 대기 (Circular wait)
해설:
소스 [90]에 따르면 교착 상태가 발생하기 위해 동시에 만족해야 하는 네 가지 필수 조건은 다음과 같습니다:
1.
상호 배제 (Mutual exclusion)
2.
점유와 대기 (Hold and wait)
3.
비선점 (No preemption)
4.
순환 대기 (Circular wait)
보기 d) **우선순위 역전(Priority inversion)**은 소스 [52]에서 교착 상태의 다른 형태 중 하나로 언급되지만, 교착 상태 자체를 특징짓는 네 가지 필수 조건에는 포함되지 않습니다. 우선순위 역전은 스케줄링 문제이며, 직접적인 교착 상태 조건은 아닙니다 (교착 상태를 유발하거나 관련된 문제로 이어질 수 있지만, 네 가지 근본 조건 중 하나로 정의되지는 않습니다).
따라서 정답은 d) 우선순위 역전 (Priority inversion) 입니다.
문제 3 (개념 적용 - 세마포어 사용)
프로세스 P1에는 S1이라는 구문이 있고, 프로세스 P2에는 S2라는 구문이 있습니다. 요구사항은 반드시 S1이 S2보다 먼저 실행되어야 한다는 것입니다. 세마포어를 사용하여 이 요구사항을 충족하는 P1과 P2의 코드를 작성하고, 사용된 세마포어의 초기값을 명시하세요.
해설:
이 문제는 특정 순서(S1 -> S2)를 강제하는 동기화 문제입니다. 소스 [32]의 예시를 참고하여 해결할 수 있습니다.synch라는 세마포어 하나를 사용하며, 이 세마포어는 P2가 S2를 실행하기 전에 P1이 S1을 완료했음을 알리는 신호 역할을 합니다.
•
세마포어 초기값: 세마포어 synch는 0으로 초기화해야 합니다 [32].
•
P1 코드: S1을 실행한 후 signal() 연산을 통해 S1이 완료되었음을 알립니다.
•
P2 코드: S2를 실행하기 전에 wait() 연산을 통해 S1이 완료될 때까지 대기합니다.
코드 예시:
// 공유 세마포어
semaphore synch = 0; // 초기값 0 [32]

// 프로세스 P1
S1;          // P1에서 실행될 구문
signal(synch); // S1이 완료되었음을 알림 [32]

// 프로세스 P2
wait(synch); // P1의 signal이 발생할 때까지 대기 [32]
S2;          // P2에서 실행될 구문 (S1 완료 후 실행됨)

P2는 wait(synch)에서 세마포어 값이 0보다 커질 때까지 대기합니다. P1이 S1을 완료하고 signal(synch)를 호출하면 세마포어 값이 1이 됩니다. 이때 P2의 wait 연산이 완료되어 S2를 실행하게 됩니다. 만약 P2가 P1보다 먼저 wait(synch)를 호출하더라도, 세마포어 값이 0이므로 S1 완료 신호가 올 때까지 대기하게 됩니다.
문제 4 (개념 적용 - 자원 할당 그래프와 교착 상태)
세 스레드 T1, T2, T3가 두 가지 자원 유형 R1 (인스턴스 1개), R2 (인스턴스 1개)를 사용합니다. 현재 자원 할당 상태는 다음과 같습니다:
•
T1은 R1을 보유하고 있습니다. T1은 R2를 요청하고 있습니다.
•
T2는 R2를 보유하고 있습니다. T2는 R1을 요청하고 있습니다.
•
T3는 어떤 자원도 보유하고 있지 않으며, 어떤 자원도 요청하고 있지 않습니다.
이 상황에서 시스템은 교착 상태에 있나요? 만약 그렇다면, 어떤 스레드들이 교착 상태에 빠져 있으며, 교착 상태의 네 가지 필수 조건 중 어떤 조건들이 만족되었는지 설명하세요. (자원 할당 그래프를 머릿속으로 그려보거나 직접 그려보세요).
해설:
이 상황에서 시스템은 교착 상태에 있습니다.
교착 상태에 빠진 스레드: T1과 T2 스레드가 교착 상태에 빠져 있습니다. T3는 어떤 자원도 대기하고 있지 않으므로 교착 상태와 무관합니다.
만족된 교착 상태 필수 조건:
1.
상호 배제 (Mutual exclusion): 자원 R1과 R2는 각각 인스턴스가 1개씩뿐이므로 (소스 [85]), 한 번에 하나의 스레드만 사용할 수 있습니다. 이 조건은 만족됩니다.
2.
점유와 대기 (Hold and wait): T1은 R1을 보유한 채 R2를 대기하고 있고, T2는 R2를 보유한 채 R1을 대기하고 있습니다. 두 스레드 모두 자원을 보유한 채 다른 자원을 대기하고 있으므로 이 조건은 만족됩니다.
3.
비선점 (No preemption): 자원은 해당 스레드가 해제하기 전까지는 강제로 빼앗을 수 없습니다. 이 조건은 일반적으로 운영체제에서 자원(특히 하드웨어 자원)에 대해 적용되므로 만족된다고 가정합니다. (문제 설명에서 자원 선점이 가능하다고 명시하지 않았으므로).
4.
순환 대기 (Circular wait): T1은 R2를 대기하고 있고, R2는 T2가 보유하고 있습니다. T2는 R1을 대기하고 있고, R1은 T1이 보유하고 있습니다. 따라서 T1 → R2 → T2 → R1 → T1 이라는 순환 대기 관계가 형성됩니다. 이 조건은 만족됩니다.
이 네 가지 조건이 모두 동시에 만족되므로 T1과 T2는 교착 상태에 빠져 자원을 영원히 기다리게 됩니다.
문제 5 (개념 적용 - 은행가 알고리즘 안전성)
다음은 자원 3종류 (A, B, C)와 스레드 4개 (T0, T1, T2, T3)가 있는 시스템의 스냅샷입니다. Available 자원은 (1, 5, 2)입니다. Max, Allocation 행렬이 다음과 같을 때, 시스템이 안전 상태인지 은행가 알고리즘의 안전성 알고리즘 (소스 [108] 참조)을 사용하여 판단하고, 안전하다면 안전 순서(safe sequence)를 하나 제시하세요.
Max 행렬: | | A | B | C | | :-: | :-: | :-: | :-: | | T0 | 6 | 0 | 1 | | T1 | 3 | 2 | 2 | | T2 | 9 | 0 | 2 | | T3 | 2 | 2 | 2 |
Allocation 행렬: | | A | B | C | | :-: | :-: | :-: | :-: | | T0 | 1 | 0 | 0 | | T1 | 2 | 0 | 0 | | T2 | 3 | 0 | 2 | | T3 | 2 | 1 | 1 |
해설:
먼저 Need 행렬을 계산합니다. Need [i, j] = Max [i, j] – Allocation [i, j] [107].
Need 행렬: | | A | B | C | | :-: | :-: | :-: | :-: | | T0 | 5 | 0 | 1 | (6-1, 0-0, 1-0) | T1 | 1 | 2 | 2 | (3-2, 2-0, 2-0) | T2 | 6 | 0 | 0 | (9-3, 0-0, 2-2) | T3 | 0 | 1 | 1 | (2-2, 2-1, 2-1)
Available 자원은 (1, 5, 2)입니다.
이제 안전성 알고리즘 (소스 [108])을 적용합니다:
1.
Work = Available = (1, 5, 2)
2.
Finish 벡터를 초기화합니다. T0, T1, T2, T3 모두 Allocation이 0이 아니므로 Finish = [false, false, false, false]로 시작합니다 (소스 [118]의 초기화 방식 적용).
3.
Finish[i] == false이고 Needi  Work를 만족하는 i를 찾습니다.
◦
T0: Need (5, 0, 1). (5, 0, 1)  (1, 5, 2) ? false (5 > 1)
◦
T1: Need (1, 2, 2). (1, 2, 2)  (1, 5, 2) ? true (1 ≤ 1, 2 ≤ 5, 2 ≤ 2) -> T1은 완료 가능합니다.
◦
T2: Need (6, 0, 0). (6, 0, 0)  (1, 5, 2) ? false (6 > 1)
◦
T3: Need (0, 1, 1). (0, 1, 1)  (1, 5, 2) ? true (0 ≤ 1, 1 ≤ 5, 1 ≤ 2) -> T3은 완료 가능합니다.
T1 또는 T3를 선택할 수 있습니다. T1을 먼저 선택해 보겠습니다.
•
T1 선택: T1이 완료되면 자원을 반환한다고 가정합니다.Work = Work + Allocation_T1 = (1, 5, 2) + (2, 0, 0) = (3, 5, 2) Finish[1] = true. Finish = [false, true, false, false]
1.
이제 Work = (3, 5, 2) 상태에서 다시 Finish[i] == false이고 Needi  Work인 i를 찾습니다.
◦
T0: Need (5, 0, 1). (5, 0, 1)  (3, 5, 2) ? false (5 > 3)
◦
T2: Need (6, 0, 0). (6, 0, 0)  (3, 5, 2) ? false (6 > 3)
◦
T3: Need (0, 1, 1). (0, 1, 1)  (3, 5, 2) ? true (0 ≤ 3, 1 ≤ 5, 1 ≤ 2) -> T3은 완료 가능합니다.
T3를 선택합니다.
•
T3 선택: T3이 완료되면 자원을 반환한다고 가정합니다.Work = Work + Allocation_T3 = (3, 5, 2) + (2, 1, 1) = (5, 6, 3) Finish[3] = true. Finish = [false, true, false, true]
1.
이제 Work = (5, 6, 3) 상태에서 다시 Finish[i] == false이고 Needi  Work인 i를 찾습니다.
◦
T0: Need (5, 0, 1). (5, 0, 1)  (5, 6, 3) ? true (5 ≤ 5, 0 ≤ 6, 1 ≤ 3) -> T0는 완료 가능합니다.
◦
T2: Need (6, 0, 0). (6, 0, 0)  (5, 6, 3) ? false (6 > 5)
T0을 선택합니다.
•
T0 선택: T0이 완료되면 자원을 반환한다고 가정합니다.Work = Work + Allocation_T0 = (5, 6, 3) + (1, 0, 0) = (6, 6, 3) Finish = true. Finish = [true, true, false, true]
1.
이제 Work = (6, 6, 3) 상태에서 다시 Finish[i] == false이고 Needi  Work인 i를 찾습니다.
◦
T2: Need (6, 0, 0). (6, 0, 0)  (6, 6, 3) ? true (6 ≤ 6, 0 ≤ 6, 0 ≤ 3) -> T2는 완료 가능합니다.
T2를 선택합니다.
•
T2 선택: T2가 완료되면 자원을 반환한다고 가정합니다.Work = Work + Allocation_T2 = (6, 6, 3) + (3, 0, 2) = (9, 6, 5) Finish[2] = true. Finish = [true, true, true, true]
1.
모든 i에 대해 Finish[i] == true입니다.
결론: 모든 스레드가 완료될 수 있는 순서를 찾았으므로, 시스템은 안전 상태에 있습니다.
안전 순서: 찾은 순서는 <T1, T3, T0, T2> 입니다. (T3를 먼저 선택했다면 <T3, T1, T0, T2> 등 다른 안전 순서도 가능합니다).
문제 6 (개념 적용 - 페이징 주소 변환 계산)
어떤 시스템은 논리 주소 공간이 2^16 바이트이고, 페이지 크기는 1024 바이트 (2^10)입니다. 페이지 테이블 베이스 레지스터(PTBR)는 1000을 가리킵니다. 다음은 주 메모리에 있는 페이지 테이블의 내용 일부입니다. 페이지 테이블 항목 크기는 4 바이트입니다.
페이지 번호
프레임 번호
0
12
1
25
2
6
3
19
4
8
...
...
CPU가 논리 주소 2500을 생성했습니다. 이 논리 주소에 해당하는 물리 주소는 무엇인가요? (소스 [143], [145] 참조)
해설:
페이징 시스템에서 논리 주소는 페이지 번호(p)와 페이지 오프셋(d)으로 나뉩니다 [143]. 물리 주소는 페이지 테이블에서 찾은 프레임 번호와 페이지 오프셋을 결합하여 얻습니다 [143].
1.
논리 주소 분할:
◦
논리 주소 공간 크기 = 2^16 바이트 (m = 16)
◦
페이지 크기 = 1024 바이트 = 2^10 바이트 (n = 10)
◦
페이지 번호 비트 수 = m - n = 16 - 10 = 6 비트
◦
페이지 오프셋 비트 수 = n = 10 비트
◦
논리 주소 2500을 페이지 번호와 오프셋으로 분할합니다.
◦
페이지 번호 = 논리 주소 / 페이지 크기 = 2500 / 1024 = 2 (정수 부분)
◦
페이지 오프셋 = 논리 주소 % 페이지 크기 = 2500 % 1024 = 452 따라서 논리 주소 2500은 페이지 번호 2, 페이지 오프셋 452에 해당합니다.
2.
물리 프레임 찾기:
◦
페이지 테이블은 주 메모리에 있으며, PTBR은 페이지 테이블의 시작 주소인 1000을 가리킵니다 [145].
◦
페이지 번호 2에 해당하는 페이지 테이블 항목을 찾습니다. 페이지 테이블 항목 크기는 4 바이트이므로, 페이지 번호 p의 항목은 PTBR + p * 항목 크기 주소에 있습니다.
◦
페이지 번호 2의 항목 주소 = 1000 + 2 * 4 = 1000 + 8 = 1008 주 메모리 주소 1008에 저장된 값은 페이지 번호 2에 해당하는 물리 프레임 번호입니다. 제공된 페이지 테이블 내용에서 페이지 번호 2는 프레임 번호 6에 매핑됩니다.
◦
프레임 번호 = 6
3.
물리 주소 계산:
◦
물리 주소는 프레임 번호와 페이지 오프셋을 결합하여 얻습니다 [143]. 물리 주소 = 프레임 번호 * 페이지 크기 + 페이지 오프셋.
◦
물리 주소 = 6 * 1024 + 452 = 6144 + 452 = 6596
결론: 논리 주소 2500에 해당하는 물리 주소는 6596입니다.
문제 7 (오류 찾기 - 세마포어 사용)
다음은 두 스레드가 공유 자원에 대해 상호 배제를 보장하려 세마포어를 사용한 의사 코드입니다. 이 코드에는 심각한 오류가 포함되어 있습니다. 오류를 식별하고, 왜 그것이 오류인지 설명한 후, 올바르게 동작하도록 코드를 수정하세요.
// 공유 세마포어
semaphore mutex = 1; // 초기값 1

// 스레드 A
wait(mutex);
// 임계 구역
signal(mutex);
signal(mutex); // <-- 오류 발생 라인?

// 스레드 B
wait(mutex);
// 임계 구역
signal(mutex);

해설:
**오류 식별:**스레드 A의 코드에서 임계 구역을 빠져나온 후 signal(mutex);를 두 번 호출하고 있습니다. 소스 [39]에서 세마포어 연산의 잘못된 사용 예시로 signal(mutex) ... wait(mutex)가 언급되었으며, 이는 여러 프로세스가 동시에 임계 구역에 들어갈 수 있게 한다고 설명됩니다. 여기서 스레드 A는 락을 한 번 획득하고 한 번 해제해야 하는데, 두 번 해제하는 상황입니다.
오류 설명: mutex 세마포어는 공유 자원에 대한 접근을 제어하는 이진 세마포어 (또는 뮤텍스)로 사용됩니다. 초기값은 1입니다. 스레드 A가 wait(mutex)를 호출하면 mutex 값이 0이 되고 임계 구역에 진입합니다. 스레드 A가 첫 번째 signal(mutex)를 호출하면 mutex 값이 1이 되어 락이 해제됩니다.문제는 스레드 A가 두 번째 signal(mutex)를 호출하는 것입니다. 이 호출로 인해 mutex 값은 2가 됩니다. 이때 만약 스레드 B가 임계 구역에 진입하기 위해 wait(mutex)를 호출하면, mutex 값이 2이므로 대기 없이 통과하게 됩니다 (mutex 값은 1이 됩니다). 만약 다른 스레드 (또는 스레드 A 자체)가 또 wait(mutex)를 호출하더라도 mutex 값이 1이므로 대기 없이 통과하여 mutex 값은 0이 됩니다. 결과적으로, mutex 값이 1보다 커질 수 있으며, 이는 하나 이상의 스레드가 동시에 임계 구역에 진입하는 것을 허용하게 되어 상호 배제 요구사항을 위반합니다.
**수정된 코드:**스레드 A는 임계 구역을 빠져나온 후 signal(mutex)를 한 번만 호출해야 합니다.
// 공유 세마포어
semaphore mutex = 1; // 초기값 1

// 스레드 A
wait(mutex);
// 임계 구역
signal(mutex); // 올바른 위치에서 한 번만 호출

// 스레드 B
wait(mutex);
// 임계 구역
signal(mutex);

이렇게 수정하면 스레드 A가 임계 구역을 빠져나올 때 mutex 값이 정확히 1로 복원되어, 한 번에 하나의 스레드만 임계 구역에 접근할 수 있게 됩니다.
문제 8 (오류 찾기 - 교착 상태 예방)
다음은 교착 상태 예방을 위한 접근 방식에 대한 설명입니다. 이 설명에는 교착 상태의 네 가지 필수 조건 중 하나를 위반하려는 시도가 포함되어 있지만, 그 설명 자체에 오류가 있습니다. 오류를 찾아 왜 오류인지 설명하고, 해당 조건을 위반하는 올바른 예방 방식을 간략히 설명하세요.
"교착 상태를 예방하기 위해 '점유와 대기' 조건을 위반하는 방법은, 프로세스가 필요한 자원을 모두 한 번에 요청하는 대신, 실행 중간에 필요한 자원이 생길 때마다 그때그때 요청하고 획득하는 것입니다. 이렇게 하면 프로세스가 이미 보유한 자원을 놓지 않고 새로운 자원을 기다리는 상황을 줄일 수 있습니다."
해설:
**오류 식별:**오류는 "점유와 대기' 조건을 위반하는 방법은, 프로세스가 필요한 자원을 모두 한 번에 요청하는 대신, 실행 중간에 필요한 자원이 생길 때마다 그때그때 요청하고 획득하는 것입니다" 라는 부분에 있습니다.
**오류 설명:**소스 [91]에 따르면, '점유와 대기' 조건을 위반하는 방법은 프로세스가 자원을 요청할 때 다른 자원을 보유하고 있지 않도록 보장하는 것입니다. 이를 위한 전략 중 하나는 프로세스가 실행을 시작하기 전에 필요한 모든 자원을 요청하고 할당받는 것입니다 [91]. 다른 전략은 프로세스가 할당된 자원이 없을 때만 자원을 요청하도록 허용하는 것입니다 [91]. 문제 설명에서 제시된 방식("실행 중간에 필요한 자원이 생길 때마다 그때그때 요청하고 획득하는 것")은 오히려 점유와 대기 조건이 발생하는 일반적인 상황입니다. 프로세스는 이미 자원을 보유한 상태에서(점유) 새로운 자원을 요청하고 그 자원이 사용 불가능하면 대기하게 됩니다(대기).
올바른 예방 방식 설명:'점유와 대기' 조건을 위반하는 올바른 예방 방식은 다음과 같습니다 (소스 [91] 참조):
1.
모든 자원을 한 번에 요청: 프로세스가 실행을 시작하기 전에 필요할 수 있는 모든 자원을 미리 요청하고 할당받습니다. 필요한 모든 자원을 얻을 때까지 실행을 시작하지 않습니다. (단점: 자원 활용률 저하, 굶주림 가능성).
2.
자원을 보유하지 않은 상태에서만 요청: 프로세스가 현재 아무런 자원도 보유하고 있지 않을 때만 새로운 자원을 요청할 수 있습니다. 자원을 보유한 상태에서 추가 자원이 필요한 경우, 현재 보유한 자원을 모두 해제한 후에 필요한 자원 전체(기존 자원 포함)를 다시 요청해야 합니다.
문제 설명은 '점유와 대기'를 위반하려는 시도를 설명했지만, 실제로는 그 조건을 만족시키는 상황을 설명하고 있습니다.
문제 9 (개념 비교 - 연속 메모리 할당 전략)
연속 메모리 할당에서 빈 홀(hole) 목록에서 프로세스에게 메모리를 할당할 때 First-fit과 Best-fit 전략(소스 [138] 참조)을 사용할 수 있습니다. 두 전략의 장단점을 비교하고, 어떤 전략이 평균적으로 더 나은 메모리 공간 활용을 제공하며, 그 이유는 무엇인지 간략히 설명하세요.
해설:
First-fit 전략:
•
장점: 빈 홀 목록에서 프로세스 크기보다 크거나 같은 첫 번째 홀을 찾으면 즉시 할당하므로 빠릅니다. 전체 목록을 검색할 필요가 없습니다 (운영체제가 목록을 어떻게 관리하는지에 따라 다름).
•
단점: 더 큰 홀의 시작 부분에 작은 프로세스를 할당하여 해당 큰 홀을 작은 홀로 쪼갤 수 있습니다. 이는 목록의 앞부분에 작은 단편들이 많이 생성되게 하여 외부 단편화(external fragmentation)를 유발할 수 있습니다. 소스 [139]에서는 First-fit이 50% 규칙을 따르는 경향이 있다고 언급됩니다.
Best-fit 전략:
•
장점: 프로세스 크기에 가장 잘 맞는 (즉, 충분히 큰 홀 중 가장 작은) 홀을 할당하므로, 할당 후 남는 단편(hole) 크기가 가장 작습니다 [138]. 이는 평균적으로 더 나은 메모리 공간 활용을 제공합니다 [138].
•
단점: 가장 적합한 홀을 찾기 위해 빈 홀 목록 전체(크기 순으로 정렬되지 않은 경우)를 검색해야 할 수 있으므로 First-fit보다 느릴 수 있습니다. 또한, 할당 후 남는 매우 작은 단편들이 많이 생성되어 이 단편들은 너무 작아 나중에 어떤 프로세스에게도 할당되지 못하고 낭비될 수 있습니다.
**메모리 공간 활용:**소스 [138]에 따르면 First-fit과 Best-fit 모두 Worst-fit보다 속도 및 저장 공간 활용 측면에서 우수하며, 일반적으로 Best-fit이 평균적으로 더 나은 메모리 공간 활용을 제공합니다. 그 이유는 Best-fit이 남은 단편의 크기를 최소화하려고 시도하기 때문입니다. 반면 First-fit은 큰 홀을 불필요하게 쪼개서 큰 요청을 만족시키기 어려운 작은 단편들을 앞쪽에 남겨둘 수 있습니다.
문제 10 (개념 비교 - 페이징 대 연속 할당)
페이징(Paging)과 연속 메모리 할당(Contiguous Memory Allocation)은 주 메모리를 관리하는 두 가지 주요 방식입니다. 페이징이 연속 메모리 할당에 비해 가지는 가장 큰 장점은 무엇인가요? 또한, 페이징 방식의 주요 단점은 무엇인가요? (소스 [141], [142], [138], [139] 참조)
해설:
**페이징의 가장 큰 장점:**페이징은 프로세스의 물리 주소 공간이 비연속적일 수 있도록 허용합니다 [141]. 즉, 프로세스의 페이지는 물리 메모리의 어느 빈 프레임에나 로드될 수 있습니다 [141]. 이로 인해 외부 단편화(external fragmentation) 문제를 근본적으로 해결합니다 [142]. 연속 메모리 할당에서는 사용 가능한 총 메모리 공간이 프로세스 크기보다 크더라도 연속적인 공간이 없어 할당하지 못하는 외부 단편화가 발생하지만 [138], 페이징은 고정 크기의 프레임 단위로 할당하므로 이러한 문제가 없습니다.
**페이징의 주요 단점:**페이징의 주요 단점 중 하나는 **내부 단편화(internal fragmentation)**가 발생할 수 있다는 것입니다 [142]. 프로세스 크기가 페이지 크기의 정수 배수가 아닐 경우, 마지막 페이지에 해당하는 프레임의 일부 공간이 사용되지 않고 남게 됩니다 (소스 [144]의 계산 예시 참조). 또한, 페이지 테이블을 저장하기 위한 추가적인 메모리 공간이 필요하며 [145, 151], 특히 큰 주소 공간이나 작은 페이지 크기를 사용하는 경우 페이지 테이블이 매우 커질 수 있어 관리의 복잡성이 증가하고 추가 메모리 접근 비용이 발생할 수 있습니다 (소스 [145]). 두 번의 메모리 접근 문제(PTBR + 데이터/명령어)는 TLB를 통해 완화되지만 [145], 여전히 TLB 미스 시 추가적인 오버헤드가 있습니다 [147].

